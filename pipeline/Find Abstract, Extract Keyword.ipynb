{"cells":[{"cell_type":"markdown","metadata":{"id":"yp4GCYEN1ewf"},"source":["Depedencies installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29180,"status":"ok","timestamp":1684979322926,"user":{"displayName":"Aulia Khilmi Rizgi","userId":"16465661636667067588"},"user_tz":-540},"id":"WgyEfu4M1NkM","outputId":"1fdbc814-db23-44b9-fa7c-eb0a93090571"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pymupdf in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (1.22.3)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: KeyBERT in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (0.7.0)\n","Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from KeyBERT) (1.24.3)\n","Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from KeyBERT) (1.2.2)\n","Requirement already satisfied: rich>=10.4.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from KeyBERT) (13.4.2)\n","Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from KeyBERT) (2.2.2)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from rich>=10.4.0->KeyBERT) (2.15.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from rich>=10.4.0->KeyBERT) (3.0.0)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn>=0.22.2->KeyBERT) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn>=0.22.2->KeyBERT) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn>=0.22.2->KeyBERT) (1.10.1)\n","Requirement already satisfied: tqdm in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (4.65.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (4.30.1)\n","Requirement already satisfied: torch>=1.6.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (2.0.1)\n","Requirement already satisfied: nltk in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (3.8.1)\n","Requirement already satisfied: sentencepiece in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (0.1.99)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (0.15.1)\n","Requirement already satisfied: torchvision in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sentence-transformers>=0.3.8->KeyBERT) (0.15.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (23.0)\n","Requirement already satisfied: filelock in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (3.12.1)\n","Requirement already satisfied: requests in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (2.29.0)\n","Requirement already satisfied: fsspec in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (2023.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (6.0)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->KeyBERT) (0.1.2)\n","Requirement already satisfied: networkx in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->KeyBERT) (3.1)\n","Requirement already satisfied: sympy in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->KeyBERT) (1.12)\n","Requirement already satisfied: jinja2 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->KeyBERT) (3.1.2)\n","Requirement already satisfied: colorama in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->KeyBERT) (0.4.6)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->KeyBERT) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->KeyBERT) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->KeyBERT) (0.3.1)\n","Requirement already satisfied: click in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->KeyBERT) (8.0.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->KeyBERT) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->KeyBERT) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (1.26.16)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (2023.5.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->KeyBERT) (2.0.4)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->KeyBERT) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: yake in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (0.4.8)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: networkx in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (3.1)\n","Requirement already satisfied: jellyfish in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (0.11.2)\n","Requirement already satisfied: segtok in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (1.5.11)\n","Requirement already satisfied: click>=6.0 in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (8.0.4)\n","Requirement already satisfied: numpy in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (1.24.3)\n","Requirement already satisfied: tabulate in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from yake) (0.9.0)\n","Requirement already satisfied: colorama in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from click>=6.0->yake) (0.4.6)\n","Requirement already satisfied: regex in c:\\users\\dc13208\\appdata\\local\\anaconda3\\envs\\py310\\lib\\site-packages (from segtok->yake) (2023.6.3)\n"]}],"source":["%pip install pymupdf\n","%pip install KeyBERT\n","%pip install yake"]},{"cell_type":"markdown","metadata":{"id":"IOguzq3B1j4s"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":14905,"status":"ok","timestamp":1684979337803,"user":{"displayName":"Aulia Khilmi Rizgi","userId":"16465661636667067588"},"user_tz":-540},"id":"2XG5JmK41jZU"},"outputs":[],"source":["# Import widget\n","from IPython.display import Image as IPImage, display, HTML\n","from ipywidgets import interact, Select, SelectMultiple, HBox, VBox, interactive_output, widgets, Layout\n","import warnings\n","\n","# Other\n","import glob, os, sys, re\n","\n","# Local\n","import util"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1684979337804,"user":{"displayName":"Aulia Khilmi Rizgi","userId":"16465661636667067588"},"user_tz":-540},"id":"zyF9fqtz2DbT"},"outputs":[],"source":["text_path = \"../output/\"\n","opt = ['text', 'metadata']"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def read_text_file(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","    return content"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473,"referenced_widgets":["495497a74a904603890cca6573c5a08e","9d4a3277258c43108f4e9b2594885367","32b02f4364d348d39f17dd3304b0942d","adaf3721175f4a0ab7b684181dcbaa78","4ac1758158ab4bc8873aa333301dc0bf","c0f87af0cfb54a6895af214cd76d7701","600952c10b24483e9fbe4b1ec0a3694e","63d5d46c119f49b6a8f7bcce43b62fed","02f15603278243109cbc34fb413c54e9","afe464ef307d49daa3d9c86fc8a1d8f9","f1ab3e33d6e2404c9fb2a907279e4c7f","f0ebc717e73b43c3a52967b50f5aff3d","4c8dc223d141490ca29279d9a3e4385a","c09b8528c59e46fbb727c5abc0ff3698","03cfe268ea7047789f6268406e361ebd","a333fc9847dc439a8b42d541cf57b845","d60a150880164d45b88376049df901e1","de9b5f6f7d3c4473a1862cd625df223e","b5aa942ffb914b799de1096438f893f6","76edfa22133b4d76bfb7c067a207e439","cbb750479928468290283e289144fc16","e8e57a79c0624721b0bf2de2a0888744","5ccc4da5db5b4292b0ce0457e5fff2be","433824480590471cab43e931681df862","cbdb35f562ee44e4a347b95076e75a7d","17fc5911532f4f79ba1e932752a7e44b","611d5e153dd0418e9c7b38b3a6861480","214423bbe91b4f299eec75280d403f26","afef6760867641de9d3c3f47e4ff54e6","d8a44a00a8bd4d5da2369228e8d89aa7","e08db4e997d34da89c579c97e672eeea","72004f95cbfd454997ae3013087e5cbc","011df235705c4de798bd7d909342328b","8ab9652b43114b449c9d7f290f3617f9","15cabcd05d8b412e9600ecc43225c2fb","d5bddb4874c74c079dff8ab0aea16cec","4723d2203b1d4ae8b4c9e18392e14609","6f5ffe5d2fc149d1a1c35f20d8c5c9a8","fc28e85dea7c4248a490626e86a336e0","cbef93357efb4e01ab217f87e9e6dd9d","7b535913a4d54750a724b3c4d4bc98e3","bb269f5fa69641fcb6bbe00d47b088c5","881af9e5440947f2ad10ca6973d4e31b","dba0091ec9574024a76ea441edf1e712","54bc3491b078400fa79bc6648bdf1d87","1902358cf6064e46abe5a15cfef28d45","b4d734a3156e49608227bd577bbbb411","6b760301e8bd4e518018f228d6e68a67","9abc5294d2ed4467ab6086721a703a3c","dd9c61b7c0ab4b1cb4cb28427e20de23","588831bba5c04513bca80db9dea18dc5","cd9ecb0f57844d6da5bf63fd16d6e059","77fa0ccf55d743bfa29b9e1866d837b2","90a1927c45a14d20baa3b0f80bd5beae","0dcb94d7c5ab4f46b2a58bfd52a3b264","3fc9c2fdf4bd429b85bcd3feb8ccdcf5","c578cdbf64b74df3ba9fa96405e7064a","e3d1f919971b40cf8bdf48ff4ed7b7ca","c871dbbb4b4d471e99ad921c33647084","3148954ca46545cf956d71a2c30120a0","4748ad0315aa48ef874180cbf23840e9","6b40055165c64284a7f7da1da796565e","9c800f0aa9e84e2bb0595c4be793e071","71416d81bb204cec9fb5666ff7d06b19","2ce78ce179884d4580a60106c27a24c6","20a120ede9e541bfb5f316b29a29bb5d","6135bf0bd41c4ccc88287f358390a33c","a83c68ee145245f28424f322bebb530d","c8dc3faaeb2d4d689c1cac40f4a1a0d8","e607bf085b1648189880b0ceedb45643","e5cfaade046249509aec6de1860e0974","18690d2646b54eea9affbc9349ec0051","1a783940fdfb41f4aa7b1a8392523933","3203d924a2754a0197c4179c2ea97293","4323ebbab25c4180847ecb96daa8922c","0a03f5a38e094df4916b4591f8cdf2df","3d997e9f67c74d668ec6f5534ff8c38a","465c1b67b2fb43c997e7bccc3b4853b3","f17fa9baddc549e4adea619453c78cec","fe14471e53994c2581b6edad81dc4a75","3a6d4de2d62847019db85f5355daa494","a40ae8a807154111884513aa5622418a","a2e20a0e837243b09c8a80835c31fec2","5ef0a3150aef4dedbdfc246ce7180837","e4619e9034a84321942291241d22a996","d36ce211a6224d60b35652243e5f32ab","dbd664760b274978b00516d409530803","41c3f5d7e11a4ff5af6ee524713f7af4","662d85e722f94e3ea17035e660fca3c9","dcf557c272df4329afb683984b20d5ec","c495ff0465e34095bc5f1a2f6605f36e","141a23bbb603486aa86350566af76ed3","d40983429d9c4c948c965d173188b93f","1374e8805ecd45b4b135e9a0fd58b547"]},"executionInfo":{"elapsed":1101,"status":"ok","timestamp":1684979338888,"user":{"displayName":"Aulia Khilmi Rizgi","userId":"16465661636667067588"},"user_tz":-540},"id":"tYFyyE9-7Su_","outputId":"655dde7b-9a82-48ff-838d-9e78adc81d5a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1dacffb989fa429ba55f48b1c863ee46","version_major":2,"version_minor":0},"text/plain":["HBox(children=(Select(description='PDF File', layout=Layout(width='25%'), options=('2004.05150.pdf.txt', 'Abon…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98f0eb7de3504fedaa54427d6761a49d","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"}],"source":["def read_file(pdf_file, opt):\n","    global data_txt, content_txt, md_txt\n","    \n","    txt_path = text_path + \"text/\" + pdf_file\n","    md_path = text_path + \"metadata/\" + pdf_file\n","    \n","    content_txt = read_text_file(txt_path)\n","    md_txt = read_text_file(md_path)\n","\n","    if (opt == \"text\"):\n","        data_text = content_txt\n","    else:\n","        data_text = md_txt\n","    display(widgets.HTML(data_text[:1500], raw=True))\n","\n","pdf_list = [os.path.basename(file) for file in glob.iglob( text_path +'/text/*') if re.search(\".+\\.(txt)\", os.path.basename(file))]\n","\n","w1 = widgets.Select(options=pdf_list, value=pdf_list[0],rows=3, description='PDF File',disabled=False, layout=Layout(width='25%'))\n","w3 = widgets.Select(options=opt, value=opt[0],rows=3, description='Options',disabled=False, layout=Layout(width='15%'))\n","ui = HBox([w1, w3])\n","w_dict = {'pdf_file': w1, 'opt': w3}\n","out = interactive_output(read_file, w_dict)\n","display(ui, out)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Abstract Identifier"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["'— this paper describes the development of a novel non-anthropomorphic robot hand with the ability to manipulate objects by means of articulated, actively driven rollers located at the ﬁngertips. an analysis is conducted and systems of equations for two-ﬁnger and three-ﬁnger manipulation of a sphere are formulated to demonstrate full six degree of freedom nonholonomic spatial motion capability. a prototype version of the hand was constructed and used to grasp and manipulate a variety of objects. tests conducted with the prototype conﬁrmed the validity of the mathematical analysis. unlike conventional approaches to within-hand manipulation using legacy robotic hands, the continuous rotation capability of our rolling ﬁngertips allows for unbounded rotation of a grasped object without the need for ﬁnger gaiting. i. '"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["abs = util.abstract_extraction(content_txt)\n","abs"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Metadata Extraction"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["'Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["md = util.metadata_extraction(md_txt)\n","title = md[\"title\"]\n","title"]},{"cell_type":"markdown","metadata":{"id":"1ONdZ-KHODyM"},"source":["Keyword Extraction"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1047,"status":"ok","timestamp":1684983992036,"user":{"displayName":"Aulia Khilmi Rizgi","userId":"16465661636667067588"},"user_tz":-540},"id":"TK77O9gvOL7w","outputId":"46f1befb-5392-429f-d238-2ea52bf230cb"},"outputs":[{"data":{"text/plain":["[('robotic hands', 0.6193),\n"," ('roller grasper', 0.5999),\n"," ('spherical object manipulation', 0.507),\n"," ('manipulation tasks', 0.4701),\n"," ('kinematics', 0.4343)]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["kw_all = util.keywords_extraction(content_txt)\n","kw_all"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["[('robotic hands', 0.6588),\n"," ('actively driven rollers', 0.4547),\n"," ('rotation capability', 0.4538),\n"," ('nonholonomic spatial motion', 0.4159),\n"," ('rolling ﬁngertips', 0.3944)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["kw_abs = util.keywords_extraction(abs)\n","kw_abs"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Sentiment Analysis"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[{'label': 'joy', 'score': 0.8168344497680664}, {'label': 'fear', 'score': 0.10476111620664597}, {'label': 'anger', 'score': 0.05356966704130173}, {'label': 'surprise', 'score': 0.011461232788860798}, {'label': 'sadness', 'score': 0.011127215810120106}, {'label': 'love', 'score': 0.0022463654167950153}]]\n"]}],"source":["from transformers import pipeline\n","classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', top_k=None)\n","prediction = classifier(abs)\n","print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","label = [i[\"label\"] for i in prediction[0]]\n","score = [i[\"score\"] for i in prediction[0]]\n","\n","def plot_sentiment(label, score):\n","    # Create a bar plot of the sentiment score\n","    plt.bar(label, score)\n","    plt.xlabel('Sentiment Label')\n","    plt.ylabel('Sentiment Score')\n","    plt.title('Sentiment Analysis Result')\n","    plt.show()\n","\n","plot_sentiment(label, score)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Crossref"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["{'indexed': {'date-parts': [[2023, 6, 7]],\n","  'date-time': '2023-06-07T16:12:30Z',\n","  'timestamp': 1686154350659},\n"," 'reference-count': 36,\n"," 'publisher': 'IEEE',\n"," 'license': [{'start': {'date-parts': [[2020, 10, 24]],\n","    'date-time': '2020-10-24T00:00:00Z',\n","    'timestamp': 1603497600000},\n","   'content-version': 'vor',\n","   'delay-in-days': 0,\n","   'URL': 'https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html'},\n","  {'start': {'date-parts': [[2020, 10, 24]],\n","    'date-time': '2020-10-24T00:00:00Z',\n","    'timestamp': 1603497600000},\n","   'content-version': 'stm-asf',\n","   'delay-in-days': 0,\n","   'URL': 'https://doi.org/10.15223/policy-029'},\n","  {'start': {'date-parts': [[2020, 10, 24]],\n","    'date-time': '2020-10-24T00:00:00Z',\n","    'timestamp': 1603497600000},\n","   'content-version': 'stm-asf',\n","   'delay-in-days': 0,\n","   'URL': 'https://doi.org/10.15223/policy-037'}],\n"," 'content-domain': {'domain': [], 'crossmark-restriction': False},\n"," 'published-print': {'date-parts': [[2020, 10, 24]]},\n"," 'DOI': '10.1109/iros45743.2020.9340953',\n"," 'type': 'proceedings-article',\n"," 'created': {'date-parts': [[2021, 3, 15]],\n","  'date-time': '2021-03-15T14:49:56Z',\n","  'timestamp': 1615819796000},\n"," 'source': 'Crossref',\n"," 'is-referenced-by-count': 10,\n"," 'title': ['Design and Control of Roller Grasper V2 for In-Hand Manipulation'],\n"," 'prefix': '10.1109',\n"," 'author': [{'given': 'Shenli',\n","   'family': 'Yuan',\n","   'sequence': 'first',\n","   'affiliation': []},\n","  {'given': 'Lin',\n","   'family': 'Shao',\n","   'sequence': 'additional',\n","   'affiliation': []},\n","  {'given': 'Connor L.',\n","   'family': 'Yako',\n","   'sequence': 'additional',\n","   'affiliation': []},\n","  {'given': 'Alex',\n","   'family': 'Gruebele',\n","   'sequence': 'additional',\n","   'affiliation': []},\n","  {'given': 'J. Kenneth',\n","   'family': 'Salisbury',\n","   'sequence': 'additional',\n","   'affiliation': []}],\n"," 'member': '263',\n"," 'reference': [{'key': 'ref33',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/70.88036'},\n","  {'key': 'ref32',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ROBOT.2009.5152385'},\n","  {'key': 'ref31',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1016/j.robot.2004.03.002'},\n","  {'key': 'ref30',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.15607/RSS.2020.XVI.082'},\n","  {'key': 'ref36',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1007/s10851-009-0161-2'},\n","  {'key': 'ref35',\n","   'article-title': 'Dual-arm in-hand manipulation and regrasping using dexterous manipulation graphs',\n","   'author': 'cruciani',\n","   'year': '2019',\n","   'journal-title': 'arXiv preprint arXiv 1904 11382'},\n","  {'key': 'ref34',\n","   'article-title': 'Robot hands and the mechanics of manipulation',\n","   'author': 'mason',\n","   'year': '1985'},\n","  {'key': 'ref10', 'doi-asserted-by': 'publisher', 'DOI': '10.1115/1.4044163'},\n","  {'key': 'ref11',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/IROS.2012.6385939'},\n","  {'key': 'ref12',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1115/DETC2016-60354'},\n","  {'key': 'ref13',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA.2016.7487156'},\n","  {'key': 'ref14',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1177/0278364919887447'},\n","  {'key': 'ref15',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.15607/RSS.2018.XIV.058'},\n","  {'key': 'ref16',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/IROS.2018.8594303'},\n","  {'key': 'ref17',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/IROS.2017.8206014'},\n","  {'key': 'ref18',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/AIM.2016.7576796'},\n","  {'key': 'ref19',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA.2017.7989394'},\n","  {'key': 'ref28',\n","   'first-page': '627',\n","   'article-title': 'A reduction of imitation learning and structured prediction to no-regret online learning',\n","   'author': 'ross',\n","   'year': '2011',\n","   'journal-title': 'Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics'},\n","  {'key': 'ref4',\n","   'first-page': '691',\n","   'article-title': 'Design of a dextrous hand for advanced CLAWAR applications',\n","   'year': '2003',\n","   'journal-title': 'Proc 11th Int Conf Climbing Walking Robots Support Technologies Mobile Mach'},\n","  {'key': 'ref27',\n","   'first-page': '305',\n","   'article-title': 'Alvinn: An autonomous land vehicle in a neural network',\n","   'author': 'pomerleau',\n","   'year': '1989',\n","   'journal-title': 'Advances in neural information processing systems'},\n","  {'key': 'ref3',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA.2011.5979830'},\n","  {'key': 'ref6',\n","   'first-page': '2214',\n","   'article-title': 'An underactuated hand for efficient finger-gaiting-based dexterous manipulation',\n","   'author': 'ma',\n","   'year': '2014',\n","   'journal-title': 'IEEE International Conference on Robotics and Biomimetics (ROBIO) 2011'},\n","  {'key': 'ref29',\n","   'article-title': 'Algorithms for inverse reinforcement learning',\n","   'author': 'ng',\n","   'year': '0'},\n","  {'key': 'ref5',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA.2011.5980371'},\n","  {'key': 'ref8',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1177/0278364917694723'},\n","  {'key': 'ref7',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1177/0278364909360852'},\n","  {'key': 'ref2',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1146/annurev-control-060117-105003'},\n","  {'key': 'ref9',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/TRO.2016.2562122'},\n","  {'key': 'ref1',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA40945.2020.9197146'},\n","  {'key': 'ref20',\n","   'first-page': '5636',\n","   'article-title': 'In-hand manipulation using gravity and controlled slip',\n","   'author': 'karayiannidis',\n","   'year': '2015',\n","   'journal-title': '2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)'},\n","  {'key': 'ref22',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ICRA.2014.6907062'},\n","  {'key': 'ref21',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/ROBOT.1988.12056'},\n","  {'key': 'ref24',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/IROS.2015.7354264'},\n","  {'key': 'ref23',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/TRO.2017.2693391'},\n","  {'key': 'ref26',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1109/HUMANOIDS.2015.7363524'},\n","  {'key': 'ref25',\n","   'doi-asserted-by': 'publisher',\n","   'DOI': '10.1177/0278364914559753'}],\n"," 'event': {'name': '2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)',\n","  'location': 'Las Vegas, NV, USA',\n","  'start': {'date-parts': [[2020, 10, 24]]},\n","  'end': {'date-parts': [[2021, 1, 24]]}},\n"," 'container-title': ['2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)'],\n"," 'link': [{'URL': 'http://xplorestaging.ieee.org/ielx7/9340668/9340635/09340953.pdf?arnumber=9340953',\n","   'content-type': 'unspecified',\n","   'content-version': 'vor',\n","   'intended-application': 'similarity-checking'}],\n"," 'deposited': {'date-parts': [[2022, 6, 28]],\n","  'date-time': '2022-06-28T21:57:22Z',\n","  'timestamp': 1656453442000},\n"," 'score': 57.24684,\n"," 'resource': {'primary': {'URL': 'https://ieeexplore.ieee.org/document/9340953/'}},\n"," 'issued': {'date-parts': [[2020, 10, 24]]},\n"," 'references-count': 36,\n"," 'URL': 'http://dx.doi.org/10.1109/iros45743.2020.9340953',\n"," 'published': {'date-parts': [[2020, 10, 24]]}}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["crossref = util.crossref_search(title)\n","crossref"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ref33 10.1109/70.88036\n","ref32 10.1109/ROBOT.2009.5152385\n","ref31 10.1016/j.robot.2004.03.002\n","ref30 10.15607/RSS.2020.XVI.082\n","ref36 10.1007/s10851-009-0161-2\n","ref35 \n","ref34 \n","ref10 10.1115/1.4044163\n","ref11 10.1109/IROS.2012.6385939\n","ref12 10.1115/DETC2016-60354\n","ref13 10.1109/ICRA.2016.7487156\n","ref14 10.1177/0278364919887447\n","ref15 10.15607/RSS.2018.XIV.058\n","ref16 10.1109/IROS.2018.8594303\n","ref17 10.1109/IROS.2017.8206014\n","ref18 10.1109/AIM.2016.7576796\n","ref19 10.1109/ICRA.2017.7989394\n","ref28 \n","ref4 \n","ref27 \n","ref3 10.1109/ICRA.2011.5979830\n","ref6 \n","ref29 \n","ref5 10.1109/ICRA.2011.5980371\n","ref8 10.1177/0278364917694723\n","ref7 10.1177/0278364909360852\n","ref2 10.1146/annurev-control-060117-105003\n","ref9 10.1109/TRO.2016.2562122\n","ref1 10.1109/ICRA40945.2020.9197146\n","ref20 \n","ref22 10.1109/ICRA.2014.6907062\n","ref21 10.1109/ROBOT.1988.12056\n","ref24 10.1109/IROS.2015.7354264\n","ref23 10.1109/TRO.2017.2693391\n","ref26 10.1109/HUMANOIDS.2015.7363524\n","ref25 10.1177/0278364914559753\n"]}],"source":["for ref in crossref[\"reference\"]:\n","    print(ref[\"key\"], ref.get(\"DOI\", \"\"), ref.get(\"journal-title\", \"\"))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNklNxMUA7hmcRAaiN73DpZ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"011df235705c4de798bd7d909342328b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02f15603278243109cbc34fb413c54e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03cfe268ea7047789f6268406e361ebd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a03f5a38e094df4916b4591f8cdf2df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dcb94d7c5ab4f46b2a58bfd52a3b264":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1374e8805ecd45b4b135e9a0fd58b547":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"141a23bbb603486aa86350566af76ed3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d40983429d9c4c948c965d173188b93f","placeholder":"​","style":"IPY_MODEL_1374e8805ecd45b4b135e9a0fd58b547","value":"24 | Energy Environ. Sci., 2020, 13, 24--52 This journal is © The Royal Society of Chemistry 2020 Cite this: Energy Environ. Sci., 2020, 13, 24 Conjugated polymers for visible-light-driven photocatalysis Chunhui Dai and Bin Liu * Conjugated polymers have recently been under active investigation as promising alternatives to traditional inorganic semiconductors for photocatalysis. This is due to their unique advantages of low cost, high chemical stability, and molecularly tunable optoelectronic properties. This critical review summarizes the recent advancements in p-conjugated polymers for visible-light-driven photocatalytic applications including water splitting, CO2 reduction, organic transformation and degradation of organic dyes. Special emphasis is placed on how the changes in the polymer structure could influence their physicochemical properties and photocatalytic activities. This structure–activity relationship analysis should guide rational molecular design of conjugated polymers for improved photocatalytic activity. Broader context The exploitation of eﬃcient photocatalysts to directly convert the radiant sunlight into chemical energy is of great importance to address the current energy and environmental challenges. Conjugated polymers (CPs) consisting of photoactive p-systems represent an attractive platform for solar energy utilization. They have been intensively studied for a variety of photocatalytic applications and many exciting performances were reported through facile molecular design. A comprehensive review is thus timely to summarize the progress of the field. This review article systematically presents the recent advances in conjugated polymers for visible-light-driven photocatalysis, including water splitting, CO2 reduction, organic transformation and degradation of organic dyes. The synthesis and design principles of conjugated polymers in these photocatalytic applications are illustrated, with an emphasis on the correlation between polymer structures and their photocatalytic activities. We expect that the systematic discussion in this review will not only provide a general overview of the field, but also promote the development of conjugated polymers with fascinating properties for photocatalysis. 1. Introduction The sun is known as a super ‘‘energy warehouse’’ to irradiate solar light continuously to the Earth. On average, the solar energy reaching the Earth’s surface per hour is enough to meet Department of Chemical & Biomolecular Engineering, National University of Singapore, 117585, Singapore. E-mail: cheliub@nus.edu.sg Chunhui Dai Chunhui Dai obtained his PhD degree (2016) in organic chemistry from the School of Chemistry and Chemical Engineering at Nanjing University, China. He is now a Research Fellow in Prof. Bin Liu’s ofresearch group at the Department Chemical and Biomolecular Engineering, National University isof Singapore. His research interest centred on the design and synthesis of conjugated polymers for photocatalytic conversions. Bin Liu Bin Liu is currently Provost’s Chair Professor in the Department of Chemical and Biomolecular Engineering at the National University of Singapore (NUS), where she received her PhD degree in 2001. After postdoctoral work at the University of California, Santa Barbara, she joined NUS in late 2005. Her research focuses on the development of conjugated polymers and organic nanomaterials and exploration of their applications in sensing, imaging and solar energy conversion. Received 18th June 2019, Accepted 30th September 2019 DOI: 10.1039/c9ee01935a rsc.li/ees Energy & Environmental Science REVIEW Published on 01 October 2019. Downloaded on 5/10/2023 4:38:50 AM.  View Article Online View Journal  | View Issue "}},"15cabcd05d8b412e9600ecc43225c2fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5bddb4874c74c079dff8ab0aea16cec","placeholder":"​","style":"IPY_MODEL_4723d2203b1d4ae8b4c9e18392e14609","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\n\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\n\n0\n2\n0\n2\n\nv\no\nN\n7\n1\n\n]\n\nO\nR\n.\ns\nc\n[\n\n2\nv\n9\n9\n4\n8\n0\n.\n4\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\nthe ability to manipulate objects by means of active surfaces at\nthe ﬁngertips. Active surfaces are achieved by spherical rolling\nﬁngertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nof each ﬁnger, allowing the ﬁngers to grasp objects over a\nrange of size and shapes. Instantaneous kinematics was derived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\nimitation learning,\nin simulation and experimentally on the\nhardware.\n\nI. INTRODUCTION\n\nIn an effort to bring robots from the laboratory into real\nworld environments, researchers have endeavored to develop\nincreasingly dexterous robots that can interact deftly with\nobjects. In order for such robots to take on a wide range\nof everyday tasks, they need to be capable of sophisticated\nobject manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by\nreorienting objects while maintaining the grasp. Out of all\nthe grasping and manipulation tasks, in-hand manipulation\nis among the ones that require the most dexterity.\n\nA background of in-hand manipulation literature is pre-\nsented in [1] and a more extensive review of robot hands and\ngraspers is given in [2]. Common approaches to designing\nrobotic grippers that can perform in-hand manipulation are:\nanthropomorphic hands which take advantage of intrinsic\nhuman dexterity, but due to the high number of degrees\nof freedom are complex and expensive [3] [4] [5]; under-\nactuated hands which passively conform to objects, achieving\ngood grasp stability, but at the cost of the controllability\nneeded to perform many in-hand manipulation tasks [6] [7]\n[8] [9]; grippers with active surfaces (such as conveyors)\nwhich allow for the object to be manipulated without chang-\ning grasp pose, but with a ﬁxed conveyor orientation limiting\npossible motions [10] [11] [12].\n\nWe developed a novel grasper design using articulated, ac-\ntively driven spherical rollers located at the ﬁngertips, shown\nin Fig. 1. By incorporating continuous rotating mechanisms,\n\n*This work has been funded, in part, by the Stanford Interdisciplinary\nGraduate Fellowship. Detailed implementations can be found at: https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html\n\n1Department of Mechanical Engineering, Stanford University\n2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\n\njks@cs.stanford.edu\n\nFig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm.\nThree ﬁngers, each with three degrees of freedom, can grasp and reorient\nan object using rolling contact with the rubber coated rollers\n\nit is possible to create graspers that are highly capable but\nrelatively simple by design. The active surface achieved by\nrolling and reorientation of the spherical rollers allow the\ngrasper to perform in-hand manipulation without the need\nfor ﬁnger gaiting. Rolling contact on the object can be\nviewed as a motion that continuously breaks contact with\nthe object while simultaneously re-establishing contact at\nadjacent locations. The ability to reorient an object to any\npose also lessens the need to use externally actuated degrees\nof freedom (e.g. actuation of the robotic arm and wrist)\nwhich simpliﬁes the control scheme. More importantly, the\nspherical design of the ﬁnger tips allows for stable grasps\nindependent from the roller orientations, eliminating the need\nto analyze grasping modes for different combinations of\nroller orientations.\n\nLearning robust policies for in-hand manipulation has been\na long-standing challenge in robotics due to the complex-\nity of modelling the object and grasper contacts and the\ndifﬁculty of controlling ﬁnger motion in long and compli-\ncated manipulation sequences. Deep Reinforcement Learning\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object ﬁrmly and stably\nwhile transforming the object with deep reinforcement learn-\ning requires many more training episodes and a carefully\ndesigned reward function. To overcome these issues, we used\nan imitation learning based approach to learn a control policy\nin order to arbitrarily transform an object while holding it.\n\n \n \n \n \n \n \n\f"}},"17fc5911532f4f79ba1e932752a7e44b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_611d5e153dd0418e9c7b38b3a6861480","placeholder":"​","style":"IPY_MODEL_214423bbe91b4f299eec75280d403f26","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\ntheabilitytomanipulateobjectsbymeansofactivesurfacesat\n0202\nthefingertips.Activesurfacesareachievedbysphericalrolling\nfingertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nvoN of each finger, allowing the fingers to grasp objects over a\nrangeofsizeandshapes.Instantaneouskinematicswasderived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\n71 imitation learning, in simulation and experimentally on the\nhardware.\n]OR.sc[ I. INTRODUCTION\nIn an effort to bring robots from the laboratory into real\nworldenvironments,researchershaveendeavoredtodevelop\nincreasingly dexterous robots that can interact deftly with\nFig.1. TheRollerGrasperV2prototypemountedonaUR-5robotarm.\nobjects. In order for such robots to take on a wide range\nThree fingers, each with three degrees of freedom, can grasp and reorient\nof everyday tasks, they need to be capable of sophisticated anobjectusingrollingcontactwiththerubbercoatedrollers\n2v99480.4002:viXra object manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by it is possible to create graspers that are highly capable but\nreorienting objects while maintaining the grasp. Out of all relatively simple by design. The active surface achieved by\nthe grasping and manipulation tasks, in-hand manipulation rolling and reorientation of the spherical rollers allow the\nis among the ones that require the most dexterity. grasper to perform in-hand manipulation without the need\nA background of in-hand manipulation literature is pre- for finger gaiting. Rolling contact on the object can be\nsentedin[1]andamoreextensivereviewofrobothandsand viewed as a motion that continuously breaks contact with\ngraspers is given in [2]. Common approaches to designing the object while simultaneously re-establishing contact at\nrobotic grippers that can perform in-hand manipulation are: adjacent locations. The ability to reorient an object to any\nanthropomorphic hands which take advantage of intrinsic pose also lessens the need to use externally actuated degrees\nhuman dexterity, but due to the high number of degrees of freedom (e.g. actuation of the robotic arm and wrist)\nof freedom are complex and expensive [3] [4] [5]; under- which simplifies the control scheme. More importantly, the\nactuatedhandswhichpassivelyconformtoobjects,achieving spherical design of the finger tips allows for stable grasps\ngood grasp stability, but at the cost of the controllability independentfromtherollerorientations,eliminatingtheneed\nneeded to perform many in-hand manipulation tasks [6] [7] to analyze grasping modes for different combinations of\n[8] [9]; grippers with active surfaces (such as conveyors) roller orientations.\nwhichallowfortheobjecttobemanipulatedwithoutchang-\nLearningrobustpoliciesforin-handmanipulationhasbeen\ninggrasppose,butwithafixedconveyororientationlimiting\na long-standing challenge in robotics due to the complex-\npossible motions [10] [11] [12].\nity of modelling the object and grasper contacts and the\nWedevelopedanovelgrasperdesignusingarticulated,ac-\ndifficulty of controlling finger motion in long and compli-\ntivelydrivensphericalrollerslocatedatthefingertips,shown\ncatedmanipulationsequences.DeepReinforcementLearning\nin Fig. 1. By incorporating continuous rotating mechanisms,\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object firmly and stably\n*This work has been funded, in part, by the Stanford Interdisciplinary\nwhiletransformingtheobjectwithdeepreinforcementlearn-\nGraduateFellowship.Detailedimplementationscanbefoundat:https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html ing requires many more training episodes and a carefully\n1DepartmentofMechanicalEngineering,StanfordUniversity\ndesignedrewardfunction.Toovercometheseissues,weused\n2StanfordArtificialIntelligenceLab(SAIL),StanfordUniversity\nanimitationlearningbasedapproachtolearnacontrolpolicy\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\njks@cs.stanford.edu in order to arbitrarily transform an object while holding it."}},"18690d2646b54eea9affbc9349ec0051":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1902358cf6064e46abe5a15cfef28d45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a783940fdfb41f4aa7b1a8392523933":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20a120ede9e541bfb5f316b29a29bb5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"214423bbe91b4f299eec75280d403f26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ce78ce179884d4580a60106c27a24c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a120ede9e541bfb5f316b29a29bb5d","placeholder":"​","style":"IPY_MODEL_6135bf0bd41c4ccc88287f358390a33c","value":"Article Obstacles Avoidance for Mobile Robot Using Type-2 Fuzzy Logic Controller  Mohammad Al-Mallah 1, Mohammad Ali 2 and Mustafa Al-Khawaldeh 1,*  1 Department of Mechatronics Engineering, Philadelphia University, P.O. Box 1, Amman 19392, Jordan 2 Department of Electrical Engineering, Philadelphia University, P.O. Box 1, Amman 19392, Jordan * Correspondence: malkhawaldeh@philadelphia.edu.jo  Abstract: Intelligent mobile robots need to deal with different kinds of uncertainties in order to perform their tasks, such as tracking predeﬁned paths and avoiding static and dynamic obstacles until reaching their destination. In this research, a Robotino® from Festo Company was used to reach a predeﬁned target in different scenarios, autonomously, in a static and dynamic environment. A Type-2 fuzzy logic controller was used to guide and help Robotino® reach its predeﬁned destination safely. The Robotino® collects data from the environment. The rules of the Type-2 fuzzy logic controller were built from human experience. They controlled the Robotino® movement, guiding it toward its goal by controlling its linear and angular velocities, preventing it from colliding obstacles at the same time, as well. The Takagi–Sugeno–Kang (TSK) algorithm was implemented. Real-time and simulation experimental results showed the capability and effectiveness of the proposed controller, especially in dealing with uncertainty problems.  Keywords: mobile robot; Robotino®; static and dynamic obstacle-avoidance environment; Type-2 fuzzy logic controller; wireless sensor network  Citation: Al-Mallah, M.; Ali, M.;  Al-Khawaldeh, M. Obstacles  Avoidance for Mobile Robot Using  Type-2 Fuzzy Logic Controller.  Robotics 2022, 11, 130. https://  doi.org/10.3390/robotics11060130  Received: 27 September 2022  Accepted: 8 November 2022  Published: 16 November 2022  Publisher’s Note: MDPI stays neutral  with regard to jurisdictional claims in  published maps and institutional afﬁl iations.  Copyright: © 2022 by the authors.  Licensee MDPI, Basel, Switzerland.  This article is an open access article  distributed under  the terms and  conditions of the Creative Commons  Attribution (CC BY) license (https://  creativecommons.org/licenses/by/  4.0/).  1. Introduction  Nowadays, robots are an inseparable part of our life. Robots with movement ability impose themselves through many applications, including medical facilities, hospitality, entertainment, package delivery, space, and military. Recently, mobile robots have been a controlling contributor to human development and one of the fastest growth ﬁelds of scientiﬁc research. They have displayed their abilities in helping and substituting humans in many applications with high efﬁciency [1].  The obstacle avoidance is an important feature in mobile robots that enables them to reach their destination point collision free. This necessitates providing them with a decisionmaking capability for planning their path autonomously and reacting to the hazards that may hinder their movements. However, this is no longer easily achieved by using classical control approaches without prior information available about the environment and using intelligent control [1]. Furthermore, some of the intelligent control methods cannot handle the high level of uncertainties of sensors, actuators, and environment [2].  For achieving autonomous obstacle avoidance, numerous control strategies have been developed, among which is the Type-2 fuzzy logic control. Fuzzy logic control is considered the most vastly used technique for designing controllers that manage suitable performance in many real-world applications [3]. For example, it was used to design a controller capable of introducing a safe Robotino® and tracking its predeﬁned target, as in Ref. [4]. A fuzzy logic controller with 153 fuzzy rules was utilized for controlling the Robotino® path-tracking issue, while another fuzzy logic controller with 27 fuzzy rules was applied for the Robotino® obstacle-avoidance feature, using the Sugeno fuzzy algorithm. Many real-time experiments reﬂected good abilities of the proposed controllers. Moreover, an autonomous mobile robot was designed and implemented by using a fuzzy logic controller,  Robotics 2022, 11, 130. https://doi.org/10.3390/robotics11060130  https://www.mdpi.com/journal/robotics  robotics\f"}},"3148954ca46545cf956d71a2c30120a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3203d924a2754a0197c4179c2ea97293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4323ebbab25c4180847ecb96daa8922c","placeholder":"​","style":"IPY_MODEL_0a03f5a38e094df4916b4591f8cdf2df","value":"2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China  978-1-4799-3685-4/14/$31.00 ©2014 IEEE  270  In-HandPreciseTwistingandPositioningbyaNovelDexterousRoboticGripperforIndustrialHigh-SpeedAssemblyFeiChen,Member,IEEE,FerdinandoCannella,Member,IEEE,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,andDarwinCaldwell,Fellow,IEEEAbstract—Inelectronicmanufacturingsystem,thedesignoftherobotichandwithsufﬁcientdexterityandconﬁgurationisimportantforthesuccessfulaccomplishmentoftheassemblytask.Duetothegrowingdemandfromhigh-mixmanufacturingindustry,itisdifﬁcultforthetraditionalrobottograspalargenumberofassemblypartsortoolshavingcylindershapeswithcorrectpostures.Inthisresearch,anoveljawlikegripperwithhuman-sizedanthropomorphicfeaturesisdesignedforin-handprecisepositioningandtwistingonline.Itretainsthesimplicityfeatureoftraditionalindustrialgrippersanddexterityfeaturesofdexterousgrippers.Itcanapplyaconstantgrippingforceonassemblypartsandperformsreliabletwistingmovementwithinlimitedtimetomeettheindustrialrequirements.Manipulatingseveralcylindricalassemblypartsbyrobot,asanexperimentalcaseinthispaper,isstudiedtoevaluateitsperformance.Theeffectivenessofproposedgripperdesignandmechanicalanalysisisprovedbythesimulationandexperimentalresults.I.INTRODUCTIONDuringthepasttensofyear,thedevelopmentinmanu-facturingindustryhasbeendividedintothreemainstreams:MassiveProduction,MediumProductionandSmallproduc-tion.Smallproduction,usuallyfullyusingrobots,cannotkeepinstepwiththegrowingsocialdemandingforHigh-Mix,Low-Volumemanufacturing.Forthemanufacturingfullywithhumanworkers,thelaborcostisalsoincreasingrapidly.Whenaddressingthisproblem,itisimportanttobuildmoreﬂexiblesystemstoimprovethedexterityandreconﬁgurabilityofcurrentmanufacturingsystembycon-sideringcombiningandcoordinatingtheabovetworespects,consideringtheirtrade-offandimprovingtheoverallas-semblyeffectivenessandefﬁciency[1].Fromourresearch,ifwecanprovidetherobotwithsufﬁcientﬂexibilityinreconﬁguration,itcanhelpthefactoryboostingtheproductqualityandmeanwhilereducingthecost[2].Currentlyinroboticassemblycellforﬂexiblemanufac-turing,therestillremainmanyunsolvedissuesforrobots.Oneisthattherobotcannotworkefﬁcientlyindealingwithassemblypartswithcomplicatedshapes.Theyoftenrelyonexternalsensorsystemstohelpwiththeassemblywork[3].Ontheotherside,humanworkersareskilledinperformingcomplicatedtasksusingtheirhands.Inthiscase,itisessentialthattheconventionalroboticmanipulatorisabletoperformcomplicatedmanipulationlikehumanworkerFeiChen,FerdinandoCannella,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,DarwinCaldwellarewithintheDepartmentofAdvancedRobotics,IstitutoItalianodiTecnologia,Italy,16163,E-mail:{fei.chen,ferdinando.cannella,carlo.canali,traveler.hauptman,giuseppe.soﬁa,dar-win.caldwell}@iit.it.Fig.1.AssemblyscenariointhisresearchunderAUTORECONproject[4].TheobjectiveofAUTORECONprojectistodesignamanufacturingsystemwithreconﬁgurableroboticmanipulatorunderthewellcontrolledinformationﬂow.Todesignseveralreconﬁgurablerobotichandssuitableforindustrialimplementationisoneofitstasks.does.Duringthepastyearsofdevelopmentinroboticmanip-ulators,nevertheless,thebasicappearanceofthemanipulatorhasseldomchanged,anditisalsodifﬁcultontheotherhandtomodifythebasicarchitectureofrobots.Therefore,peopletendtoimprovethecapacityofrobotsbydesigningvariousfunctionalend-effectors(hands)forrobots.Inordertomeetindustrialapplicationrequirements,therobotichandsmustbeinexpensive,compact,lowweightandrobust.Italsomustbecapableofperformingsimplegraspingandmanipulationtasks,suchasprecisionmanipulation,in-handgrasptransitions,andsufﬁcientlygeneraltomanipulatedifferentobjectsandtools.Uptopresent,mostrobotichandsinbothindustrialandacademicworldsareeitherfewactuatorspoweredjaws,orsimpliﬁedhumanhandshapelikedmulti-ﬁngeredhandsforcertaingraspingpatterns.Lotsofresearchershavealreadypaidmuchattentiontodevelopsuchfunctionalroboticend-effectorsinthepast25years.Aroboticgrippercouldbeoftwoﬁngers,likeajaw[3]withtwoﬁngersinourpreviousresearch,threeﬁngers[5]orfourﬁngers[6]orevenmore,thesamewithhuman’shand[7].Parallelmanipulator[8]hasbeenalreadysuccessfullyimplementedinindustry.Theycanperformanddemonstratepickandplaceoperationsinreallyfastspeedwithhighreliability[9].Meanwhile,itismuchcheaperandsimplerthanserialmanipulators.Itiswidelyadoptedinhighspeed,high-accuracypositioningwithinonlylimitedworkspace,suchasfoodpackingandelectronicpartsplacing.Anothernoveluniversalgrippersisdeveloped,whichisabletopickupunfamiliarobjectsofwidelyvarying\f"}},"32b02f4364d348d39f17dd3304b0942d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["PDFMiner.six","PyMuPDF","PDFPlumber"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"PDF Reader","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_afe464ef307d49daa3d9c86fc8a1d8f9","rows":3,"style":"IPY_MODEL_f1ab3e33d6e2404c9fb2a907279e4c7f"}},"3a6d4de2d62847019db85f5355daa494":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d997e9f67c74d668ec6f5534ff8c38a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_465c1b67b2fb43c997e7bccc3b4853b3","placeholder":"​","style":"IPY_MODEL_f17fa9baddc549e4adea619453c78cec","value":"In-Hand Precise Twisting and Positioning by a Novel Dexterous Robotic Gripper for Industrial High-Speed Assembly Fei Chen, Member, IEEE, Ferdinando Cannella, Member, IEEE, Carlo Canali, Traveler Hauptman, Giuseppe Soﬁa, and Darwin Caldwell, Fellow, IEEE Abstract— In electronic manufacturing system, the design of the robotic hand with sufﬁcient dexterity and conﬁguration is important for the successful accomplishment of the assembly task. Due to the growing demand from high-mix manufacturing industry, it is difﬁcult for the traditional robot to grasp a large number of assembly parts or tools having cylinder shapes with correct postures. In this research, a novel jaw like gripper with human-sized anthropomorphic features is designed for in-hand precise positioning and twisting online. It retains the simplicity feature of traditional industrial grippers and dexterity features of dexterous grippers. It can apply a constant gripping force on assembly parts and performs reliable twisting movement within limited time to meet the industrial requirements. Manipulating several cylindrical assembly parts by robot, as an experimental case in this paper, is studied to evaluate its performance. The effectiveness of proposed gripper design and mechanical analysis is proved by the simulation and experimental results. I. INTRODUCTION During the past tens of year, the development in manufacturing industry has been divided into three main streams: Massive Production, Medium Production and Small production. Small production, usually fully using robots, cannot keep in step with the growing social demanding for HighMix, Low-Volume manufacturing. For the manufacturing fully with human workers, the labor cost is also increasing rapidly. When addressing this problem, it is important to build more ﬂexible systems to improve the dexterity and reconﬁgurability of current manufacturing system by considering combining and coordinating the above two respects, considering their trade-off and improving the overall assembly effectiveness and efﬁciency [1]. From our research, if we can provide the robot with sufﬁcient ﬂexibility in reconﬁguration, it can help the factory boosting the product quality and meanwhile reducing the cost [2]. Currently in robotic assembly cell for ﬂexible manufacturing, there still remain many unsolved issues for robots. One is that the robot cannot work efﬁciently in dealing with assembly parts with complicated shapes. They often rely on external sensor systems to help with the assembly work [3]. On the other side, human workers are skilled in performing complicated tasks using their hands. In this case, it is essential that the conventional robotic manipulator is able to perform complicated manipulation like human worker Fei Chen, Ferdinando Cannella, Carlo Canali, Traveler Hauptman, Giuseppe Soﬁa, Darwin Caldwell are within the Department of Advanced Robotics, Istituto Italiano di Tecnologia, Italy, 16163, E-mail: {fei.chen, ferdinando.cannella, carlo.canali, traveler.hauptman, giuseppe.soﬁa, darwin.caldwell}@iit.it. Fig. 1. Assembly scenario in this research under AUTORECON project [4]. The objective of AUTORECON project is to design a manufacturing system with reconﬁgurable robotic manipulator under the well controlled information ﬂow. To design several reconﬁgurable robotic hands suitable for industrial implementation is one of its tasks. does. During the past years of development in robotic manipulators, nevertheless, the basic appearance of the manipulator has seldom changed, and it is also difﬁcult on the other hand to modify the basic architecture of robots. Therefore, people tend to improve the capacity of robots by designing various functional end-effectors (hands) for robots. In order to meet industrial application requirements, the robotic hands must be inexpensive, compact, low weight and robust. It also must be capable of performing simple grasping and manipulation tasks, such as precision manipulation, inhand grasp transitions, and sufﬁciently general to manipulate different objects and tools. Up to present, most robotic hands in both industrial and academic worlds are either few actuators powered jaws, or simpliﬁed human hand shape liked multi-ﬁngered hands for certain grasping patterns. Lots of researchers have already paid much attention to develop such functional robotic end-effectors in the past 25 years. A robotic gripper could be of two ﬁngers, like a jaw [3] with two ﬁngers in our previous research, three ﬁngers [5] or four ﬁngers [6] or even more, the same with human’s hand [7]. Parallel manipulator [8] has been already successfully implemented in industry. They can perform and demonstrate pick and place operations in really fast speed with high reliability [9]. Meanwhile, it is much cheaper and simpler than serial manipulators. It is widely adopted in high speed, high-accuracy positioning within only limited workspace, such as food packing and electronic parts placing. Another novel universal grippers is developed, which is able to pick up unfamiliar objects of widely varying 2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China 978-1-4799-3685-4/14/$31.00 ©2014 IEEE 270 "}},"3fc9c2fdf4bd429b85bcd3feb8ccdcf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c578cdbf64b74df3ba9fa96405e7064a","placeholder":"​","style":"IPY_MODEL_e3d1f919971b40cf8bdf48ff4ed7b7ca","value":"This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/LRA.2020.3007411, IEEE Robotics and Automation Letters  2377-3766 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. Authorized licensed use limited to: Carleton University. Downloaded on July 11,2020 at 02:10:16 UTC from IEEE Xplore.  Restrictions apply.   IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,20201ADexterousSoftRoboticHandforDelicateIn-HandManipulationSylvainAbondance∗1,2,ClarkB.Teeple∗1,andRobertJ.Wood1Abstract—Inthiswork,weshowthatsoftrobotichandsprovidearobustmeansofperformingbasicprimitivesofin-handmanipulationinthepresenceofuncertainty.Weﬁrstdiscussthedesignofaprototypehandwithdexteroussoftﬁngerscapableofmovingobjectswithinthehandusingseveralbasicmotionprimitives.Wethenempiricallyvalidatetheabilityofthehandtoperformthedesiredobjectmotionprimitiveswhilestillmaintainingstronggraspingcapabilities.Basedontheseprimitives,weexamineasimple,heuristicﬁngergaitwhichenablescontinuousobjectrotationforawidevarietyofobjectshapesandsizes.Finally,wedemonstratetheutilityofourdexteroussoftrobotichandinthreereal-worldcases:unscrewingthecapofajar,orientingfooditemsforpackaging,andgravitycompensationduringgrasping.Overall,weshowthatevenforcomplextaskssuchasin-handmanipulation,softrobotscanperformrobustlywithouttheneedforlocalsensingorcomplexcontrol.IndexTerms—In-HandManipulation,SoftRobotApplications,DexterousManipulationI.INTRODUCTIONMANIPULATINGobjectsintherealworldusuallyre-quiresrobotstoaccommodatearelativelylargedegreeofuncertaintyintheshape,size,andposeofobjectsintheenvironment[1].Inadditiontoenvironmentaluncertainty,targetobjectsareoftenlocatedinhighly-constrainedpositions,ormustbeplacedintonewpositionsthatareoutsidethedexterousworkspaceofthearm.Targetobjectsorworldfeaturesarealsocommonlyfragileordelicate,especiallyinapplicationswithinthehome.Manyactivitiesofdailylife(ADL)involveallthreeofthesechallenges[2],suchassettingatablewithfragiledishesorstoringdelicateproduceitemsinarefrigeratorwithoutbruisingthem.Anotherusefulskillforreal-worldmanipulationistheabilitytochangeanobject’sposewithoutusingexternalsurfaces,evenwhenthearm’srangeofmotionislimitedinsomeway.Forexample,re-graspinganobjecttoimprovethegraspqualityhasbeenstudiedextensively[3],[4].However,ManuscriptReceived:Feb.24,2020;RevisedMay28,2020;AcceptedJune23,2020.ThispaperwasrecommendedforpublicationbyEditorHongLiuuponevaluationoftheAssociateEditorandReviewers’comments.ThisworkwassupportedbytheWyssInstituteforBiologically-InspiredEngineeringandtheNationalScienceFoundation.*Theﬁrsttwoauthorscontributedequallytothiswork.1JohnA.PaulsonSchoolofEngineeringandAppliedSciences,HarvardUniversity,60OxfordSt.CambridgeMA02138,USA2´Ecolepolytechniquef´ed´eraledeLausanne(EPFL),RouteCantonale,1015Lausanne,SwitzerlandAllcorrespondencesshouldbeaddressedtoClarkTeepleorRobertWood(cbteeple@g.harvard.edu,rjwood@seas.harvard.edu).DigitalObjectIdentiﬁer(DOI):seetopofthispage.Fig.1.Oursoft,dexteroushandprototypeiscapableofperformingreal-worldmanipulationtaskswithinthehand.a)-c)Thehandisshownunscrewingthecapofanemptyplasticjarusingaheuristicﬁngergaitforrotation.d)-f)Thehandcanalsoimpartplanartranslationstoobjects.Theemptyjarwaslightlytapedtothegroundtoenableun-capping.mostexamplesrequiretherobottosetdownthetargetobjectonatabletopbeforere-grasping.Thisworkﬂowreliesonreasonablyaccuratemodelsoftheobject’sdynamics,environ-mentgeometry,andcontactdynamicsinadditiontotherobot’sowndynamics[5],[6].Alternatively,ifrobotscanmanipulatetheobjectwithintheirhands,graspscanbeadjustedwithoutrelyingonexternalsurfaces.Inrecentyears,therehasbeenasizablepushtowardutiliz-ingcompliantrobotichandsthatpassivelyadapttouncertaintyintheenvironment[7].Soft-bodiedhandsenablerobotstograspobjectsofvaryingshape,size,andposewithoutexplicitknowledgeofthoseproperties[8],[9],[10],[11].Furthermore,passivecomplianceenablesrobotstosafelyinteractwithdeli-catetargetobjectsorotherfragilefeaturesintheenvironment[12],[13],[14].Dexterousin-handmanipulationusuallyrequirespreciseplanningandcontrolofﬁngermotionbasedonmodelsoftheobjectandﬁngerswhenperformedbyrigidhands[15],[16],[17].Thisisduetocomplexcontactinteractionsbetweentheﬁngersandobject,aswellasminimalpassiveadaptationtoobjectvariation.Someattemptstomitigatethecomplexityoftheseinteractionsusingmachinelearningshowincrediblepromise,butrequireextensivetrainingonhighperformancecomputingsystems[18].However,wecanmitigatetheneed\f"}},"41c3f5d7e11a4ff5af6ee524713f7af4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4323ebbab25c4180847ecb96daa8922c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433824480590471cab43e931681df862":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465c1b67b2fb43c997e7bccc3b4853b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4723d2203b1d4ae8b4c9e18392e14609":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4748ad0315aa48ef874180cbf23840e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"495497a74a904603890cca6573c5a08e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d4a3277258c43108f4e9b2594885367","IPY_MODEL_32b02f4364d348d39f17dd3304b0942d","IPY_MODEL_adaf3721175f4a0ab7b684181dcbaa78","IPY_MODEL_4ac1758158ab4bc8873aa333301dc0bf","IPY_MODEL_c0f87af0cfb54a6895af214cd76d7701"],"layout":"IPY_MODEL_600952c10b24483e9fbe4b1ec0a3694e"}},"4ac1758158ab4bc8873aa333301dc0bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["Yes","No"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"\nReplace","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_c09b8528c59e46fbb727c5abc0ff3698","rows":3,"style":"IPY_MODEL_03cfe268ea7047789f6268406e361ebd"}},"4c8dc223d141490ca29279d9a3e4385a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54bc3491b078400fa79bc6648bdf1d87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"588831bba5c04513bca80db9dea18dc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ccc4da5db5b4292b0ce0457e5fff2be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433824480590471cab43e931681df862","placeholder":"​","style":"IPY_MODEL_cbdb35f562ee44e4a347b95076e75a7d","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\nthe ability to manipulate objects by means of active surfaces at\nthe ﬁngertips. Active surfaces are achieved by spherical rolling\nﬁngertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nof each ﬁnger, allowing the ﬁngers to grasp objects over a\nrange of size and shapes. Instantaneous kinematics was derived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\nimitation learning, in simulation and experimentally on the\nhardware.\nI. INTRODUCTION\nIn an effort to bring robots from the laboratory into real\nworld environments, researchers have endeavored to develop\nincreasingly dexterous robots that can interact deftly with\nobjects. In order for such robots to take on a wide range\nof everyday tasks, they need to be capable of sophisticated\nobject manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by\nreorienting objects while maintaining the grasp. Out of all\nthe grasping and manipulation tasks, in-hand manipulation\nis among the ones that require the most dexterity.\nA background of in-hand manipulation literature is pre-\nsented in [1] and a more extensive review of robot hands and\ngraspers is given in [2]. Common approaches to designing\nrobotic grippers that can perform in-hand manipulation are:\nanthropomorphic hands which take advantage of intrinsic\nhuman dexterity, but due to the high number of degrees\nof freedom are complex and expensive [3] [4] [5]; under-\nactuated hands which passively conform to objects, achieving\ngood grasp stability, but at the cost of the controllability\nneeded to perform many in-hand manipulation tasks [6] [7]\n[8] [9]; grippers with active surfaces (such as conveyors)\nwhich allow for the object to be manipulated without chang-\ning grasp pose, but with a ﬁxed conveyor orientation limiting\npossible motions [10] [11] [12].\nWe developed a novel grasper design using articulated, ac-\ntively driven spherical rollers located at the ﬁngertips, shown\nin Fig. 1. By incorporating continuous rotating mechanisms,\n*This work has been funded, in part, by the Stanford Interdisciplinary\nGraduate Fellowship. Detailed implementations can be found at: https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html\n1Department of Mechanical Engineering, Stanford University\n2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\njks@cs.stanford.edu\nFig. 1.\nThe Roller Grasper V2 prototype mounted on a UR-5 robot arm.\nThree ﬁngers, each with three degrees of freedom, can grasp and reorient\nan object using rolling contact with the rubber coated rollers\nit is possible to create graspers that are highly capable but\nrelatively simple by design. The active surface achieved by\nrolling and reorientation of the spherical rollers allow the\ngrasper to perform in-hand manipulation without the need\nfor ﬁnger gaiting. Rolling contact on the object can be\nviewed as a motion that continuously breaks contact with\nthe object while simultaneously re-establishing contact at\nadjacent locations. The ability to reorient an object to any\npose also lessens the need to use externally actuated degrees\nof freedom (e.g. actuation of the robotic arm and wrist)\nwhich simpliﬁes the control scheme. More importantly, the\nspherical design of the ﬁnger tips allows for stable grasps\nindependent from the roller orientations, eliminating the need\nto analyze grasping modes for different combinations of\nroller orientations.\nLearning robust policies for in-hand manipulation has been\na long-standing challenge in robotics due to the complex-\nity of modelling the object and grasper contacts and the\ndifﬁculty of controlling ﬁnger motion in long and compli-\ncated manipulation sequences. Deep Reinforcement Learning\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object ﬁrmly and stably\nwhile transforming the object with deep reinforcement learn-\ning requires many more training episodes and a carefully\ndesigned reward function. To overcome these issues, we used\nan imitation learning based approach to learn a control policy\nin order to arbitrarily transform an object while holding it.\n"}},"5ef0a3150aef4dedbdfc246ce7180837":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"600952c10b24483e9fbe4b1ec0a3694e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"611d5e153dd0418e9c7b38b3a6861480":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6135bf0bd41c4ccc88287f358390a33c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63d5d46c119f49b6a8f7bcce43b62fed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"25%"}},"662d85e722f94e3ea17035e660fca3c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcf557c272df4329afb683984b20d5ec","placeholder":"​","style":"IPY_MODEL_c495ff0465e34095bc5f1a2f6605f36e","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation Shenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2 Abstract— The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the ﬁngertips. Active surfaces are achieved by spherical rolling ﬁngertips with two degrees of freedom (DoF) – a pivoting motion for surface reorientation – and a continuous rolling motion for moving the object. A further DoF is in the base of each ﬁnger, allowing the ﬁngers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware. I. INTRODUCTION In an effort to bring robots from the laboratory into real world environments, researchers have endeavored to develop increasingly dexterous robots that can interact deftly with objects. In order for such robots to take on a wide range of everyday tasks, they need to be capable of sophisticated object manipulation. Many vital higher-level tasks will rely on a robot’s capability to perform in-hand manipulation by reorienting objects while maintaining the grasp. Out of all the grasping and manipulation tasks, in-hand manipulation is among the ones that require the most dexterity. A background of in-hand manipulation literature is presented in [1] and a more extensive review of robot hands and graspers is given in [2]. Common approaches to designing robotic grippers that can perform in-hand manipulation are: anthropomorphic hands which take advantage of intrinsic human dexterity, but due to the high number of degrees of freedom are complex and expensive [3] [4] [5]; underactuated hands which passively conform to objects, achieving good grasp stability, but at the cost of the controllability needed to perform many in-hand manipulation tasks [6] [7] [8] [9]; grippers with active surfaces (such as conveyors) which allow for the object to be manipulated without changing grasp pose, but with a ﬁxed conveyor orientation limiting possible motions [10] [11] [12]. We developed a novel grasper design using articulated, actively driven spherical rollers located at the ﬁngertips, shown in Fig. 1. By incorporating continuous rotating mechanisms, *This work has been funded, in part, by the Stanford Interdisciplinary Graduate Fellowship. Detailed implementations can be found at: https:// ccrma.stanford.edu/˜shenliy/roller_grasper_v2.html 1Department of Mechanical Engineering, Stanford University 2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University {shenliy, lins2, clyako, agruebe2}@stanford.edu, jks@cs.stanford.edu Fig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm. Three ﬁngers, each with three degrees of freedom, can grasp and reorient an object using rolling contact with the rubber coated rollers it is possible to create graspers that are highly capable but relatively simple by design. The active surface achieved by rolling and reorientation of the spherical rollers allow the grasper to perform in-hand manipulation without the need for ﬁnger gaiting. Rolling contact on the object can be viewed as a motion that continuously breaks contact with the object while simultaneously re-establishing contact at adjacent locations. The ability to reorient an object to any pose also lessens the need to use externally actuated degrees of freedom (e.g. actuation of the robotic arm and wrist) which simpliﬁes the control scheme. More importantly, the spherical design of the ﬁnger tips allows for stable grasps independent from the roller orientations, eliminating the need to analyze grasping modes for different combinations of roller orientations. Learning robust policies for in-hand manipulation has been a long-standing challenge in robotics due to the complexity of modelling the object and grasper contacts and the difﬁculty of controlling ﬁnger motion in long and complicated manipulation sequences. Deep Reinforcement Learning (DRL) has been used to learn dexterous manipulation [13] [14]. However, learning to hold the object ﬁrmly and stably while transforming the object with deep reinforcement learning requires many more training episodes and a carefully designed reward function. To overcome these issues, we used an imitation learning based approach to learn a control policy in order to arbitrarily transform an object while holding it. "}},"6b40055165c64284a7f7da1da796565e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c800f0aa9e84e2bb0595c4be793e071","placeholder":"​","style":"IPY_MODEL_71416d81bb204cec9fb5666ff7d06b19","value":"Energy & Environmental Science  REVIEW  Conjugated polymers for visible-light-driven photocatalysis  Chunhui Dai  and Bin Liu  *  Received 18th June 2019, Accepted 30th September 2019  DOI: 10.1039/c9ee01935a  Conjugated polymers have recently been under active investigation as promising alternatives to traditional  inorganic semiconductors for photocatalysis. This is due to their unique advantages of low cost, high chemical stability, and molecularly tunable optoelectronic properties. This critical review summarizes the recent advancements in p-conjugated polymers for visible-light-driven photocatalytic applications including water splitting, CO2 reduction, organic transformation and degradation of organic dyes. Special emphasis is placed on how the changes in the polymer structure could influence their physicochemical properties  and photocatalytic activities. This structure–activity relationship analysis should guide rational molecular  rsc.li/ees  design of conjugated polymers for improved photocatalytic activity.  Broader context The exploitation of eﬃcient photocatalysts to directly convert the radiant sunlight into chemical energy is of great importance to address the current energy and environmental challenges. Conjugated polymers (CPs) consisting of photoactive p-systems represent an attractive platform for solar energy utilization. They have been intensively studied for a variety of photocatalytic applications and many exciting performances were reported through facile molecular design. A comprehensive review is thus timely to summarize the progress of the field. This review article systematically presents the recent advances in conjugated polymers for visible-light-driven photocatalysis, including water splitting, CO2 reduction, organic transformation and degradation of organic dyes. The synthesis and design principles of conjugated polymers in these photocatalytic applications are illustrated, with an emphasis on the correlation between polymer structures and their photocatalytic activities. We expect that the systematic discussion in this review will not only provide a general overview of the field, but also promote the development of conjugated polymers with fascinating properties for photocatalysis.  Department of Chemical & Biomolecular Engineering, National University of Singapore, 117585, Singapore. E-mail: cheliub@nus.edu.sg  1. Introduction  The sun is known as a super ‘‘energy warehouse’’ to irradiate solar light continuously to the Earth. On average, the solar energy reaching the Earth’s surface per hour is enough to meet  Chunhui Dai obtained his PhD degree (2016) in organic chemistry from the School of Chemistry and Chemical Engineering at Nanjing University, China. He is now a Research Fellow in Prof. Bin Liu’s research group at the Department of Chemical and Biomolecular Engineering, National University of Singapore. His research interest centred on the design and is synthesis of conjugated polymers for photocatalytic conversions.  Bin Liu  Bin Liu is currently Provost’s Chair Professor in the Department of Chemical and Biomolecular Engineering at the National University of Singapore (NUS), where she received her PhD degree in 2001. the After postdoctoral work at University of California, Santa Barbara, she joined NUS in late 2005. Her research focuses on the development of conjugated polymers and organic nanomaterials and exploration of their applications in sensing, imaging and solar energy conversion.  Chunhui Dai  24|EnergyEnviron.Sci.,2020,13,24--52Thisjournalis©TheRoyalSocietyofChemistry2020Citethis:EnergyEnviron.Sci.,2020,13,24Published on 01 October 2019. Downloaded on 5/10/2023 4:38:50 AM. View Article OnlineView Journal | View Issue\f"}},"6b760301e8bd4e518018f228d6e68a67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5ffe5d2fc149d1a1c35f20d8c5c9a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc28e85dea7c4248a490626e86a336e0","placeholder":"​","style":"IPY_MODEL_cbef93357efb4e01ab217f87e9e6dd9d","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\ntheabilitytomanipulateobjectsbymeansofactivesurfacesat\n0202\nthefingertips.Activesurfacesareachievedbysphericalrolling\nfingertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nvoN of each finger, allowing the fingers to grasp objects over a\nrangeofsizeandshapes.Instantaneouskinematicswasderived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\n71 imitation learning, in simulation and experimentally on the\nhardware.\n]OR.sc[ I. INTRODUCTION\nIn an effort to bring robots from the laboratory into real\nworldenvironments,researchershaveendeavoredtodevelop\nincreasingly dexterous robots that can interact deftly with\nFig.1. TheRollerGrasperV2prototypemountedonaUR-5robotarm.\nobjects. In order for such robots to take on a wide range\nThree fingers, each with three degrees of freedom, can grasp and reorient\nof everyday tasks, they need to be capable of sophisticated anobjectusingrollingcontactwiththerubbercoatedrollers\n2v99480.4002:viXra object manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by it is possible to create graspers that are highly capable but\nreorienting objects while maintaining the grasp. Out of all relatively simple by design. The active surface achieved by\nthe grasping and manipulation tasks, in-hand manipulation rolling and reorientation of the spherical rollers allow the\nis among the ones that require the most dexterity. grasper to perform in-hand manipulation without the need\nA background of in-hand manipulation literature is pre- for finger gaiting. Rolling contact on the object can be\nsentedin[1]andamoreextensivereviewofrobothandsand viewed as a motion that continuously breaks contact with\ngraspers is given in [2]. Common approaches to designing the object while simultaneously re-establishing contact at\nrobotic grippers that can perform in-hand manipulation are: adjacent locations. The ability to reorient an object to any\nanthropomorphic hands which take advantage of intrinsic pose also lessens the need to use externally actuated degrees\nhuman dexterity, but due to the high number of degrees of freedom (e.g. actuation of the robotic arm and wrist)\nof freedom are complex and expensive [3] [4] [5]; under- which simplifies the control scheme. More importantly, the\nactuatedhandswhichpassivelyconformtoobjects,achieving spherical design of the finger tips allows for stable grasps\ngood grasp stability, but at the cost of the controllability independentfromtherollerorientations,eliminatingtheneed\nneeded to perform many in-hand manipulation tasks [6] [7] to analyze grasping modes for different combinations of\n[8] [9]; grippers with active surfaces (such as conveyors) roller orientations.\nwhichallowfortheobjecttobemanipulatedwithoutchang-\nLearningrobustpoliciesforin-handmanipulationhasbeen\ninggrasppose,butwithafixedconveyororientationlimiting\na long-standing challenge in robotics due to the complex-\npossible motions [10] [11] [12].\nity of modelling the object and grasper contacts and the\nWedevelopedanovelgrasperdesignusingarticulated,ac-\ndifficulty of controlling finger motion in long and compli-\ntivelydrivensphericalrollerslocatedatthefingertips,shown\ncatedmanipulationsequences.DeepReinforcementLearning\nin Fig. 1. By incorporating continuous rotating mechanisms,\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object firmly and stably\n*This work has been funded, in part, by the Stanford Interdisciplinary\nwhiletransformingtheobjectwithdeepreinforcementlearn-\nGraduateFellowship.Detailedimplementationscanbefoundat:https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html ing requires many more training episodes and a carefully\n1DepartmentofMechanicalEngineering,StanfordUniversity\ndesignedrewardfunction.Toovercometheseissues,weused\n2StanfordArtificialIntelligenceLab(SAIL),StanfordUniversity\nanimitationlearningbasedapproachtolearnacontrolpolicy\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\njks@cs.stanford.edu in order to arbitrarily transform an object while holding it."}},"71416d81bb204cec9fb5666ff7d06b19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72004f95cbfd454997ae3013087e5cbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_011df235705c4de798bd7d909342328b","placeholder":"​","style":"IPY_MODEL_8ab9652b43114b449c9d7f290f3617f9","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\ntheabilitytomanipulateobjectsbymeansofactivesurfacesat\n0202\nthefingertips.Activesurfacesareachievedbysphericalrolling\nfingertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nvoN of each finger, allowing the fingers to grasp objects over a\nrangeofsizeandshapes.Instantaneouskinematicswasderived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\n71 imitation learning, in simulation and experimentally on the\nhardware.\n]OR.sc[ I. INTRODUCTION\nIn an effort to bring robots from the laboratory into real\nworldenvironments,researchershaveendeavoredtodevelop\nincreasingly dexterous robots that can interact deftly with\nFig.1. TheRollerGrasperV2prototypemountedonaUR-5robotarm.\nobjects. In order for such robots to take on a wide range\nThree fingers, each with three degrees of freedom, can grasp and reorient\nof everyday tasks, they need to be capable of sophisticated anobjectusingrollingcontactwiththerubbercoatedrollers\n2v99480.4002:viXra object manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by it is possible to create graspers that are highly capable but\nreorienting objects while maintaining the grasp. Out of all relatively simple by design. The active surface achieved by\nthe grasping and manipulation tasks, in-hand manipulation rolling and reorientation of the spherical rollers allow the\nis among the ones that require the most dexterity. grasper to perform in-hand manipulation without the need\nA background of in-hand manipulation literature is pre- for finger gaiting. Rolling contact on the object can be\nsentedin[1]andamoreextensivereviewofrobothandsand viewed as a motion that continuously breaks contact with\ngraspers is given in [2]. Common approaches to designing the object while simultaneously re-establishing contact at\nrobotic grippers that can perform in-hand manipulation are: adjacent locations. The ability to reorient an object to any\nanthropomorphic hands which take advantage of intrinsic pose also lessens the need to use externally actuated degrees\nhuman dexterity, but due to the high number of degrees of freedom (e.g. actuation of the robotic arm and wrist)\nof freedom are complex and expensive [3] [4] [5]; under- which simplifies the control scheme. More importantly, the\nactuatedhandswhichpassivelyconformtoobjects,achieving spherical design of the finger tips allows for stable grasps\ngood grasp stability, but at the cost of the controllability independentfromtherollerorientations,eliminatingtheneed\nneeded to perform many in-hand manipulation tasks [6] [7] to analyze grasping modes for different combinations of\n[8] [9]; grippers with active surfaces (such as conveyors) roller orientations.\nwhichallowfortheobjecttobemanipulatedwithoutchang-\nLearningrobustpoliciesforin-handmanipulationhasbeen\ninggrasppose,butwithafixedconveyororientationlimiting\na long-standing challenge in robotics due to the complex-\npossible motions [10] [11] [12].\nity of modelling the object and grasper contacts and the\nWedevelopedanovelgrasperdesignusingarticulated,ac-\ndifficulty of controlling finger motion in long and compli-\ntivelydrivensphericalrollerslocatedatthefingertips,shown\ncatedmanipulationsequences.DeepReinforcementLearning\nin Fig. 1. By incorporating continuous rotating mechanisms,\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object firmly and stably\n*This work has been funded, in part, by the Stanford Interdisciplinary\nwhiletransformingtheobjectwithdeepreinforcementlearn-\nGraduateFellowship.Detailedimplementationscanbefoundat:https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html ing requires many more training episodes and a carefully\n1DepartmentofMechanicalEngineering,StanfordUniversity\ndesignedrewardfunction.Toovercometheseissues,weused\n2StanfordArtificialIntelligenceLab(SAIL),StanfordUniversity\nanimitationlearningbasedapproachtolearnacontrolpolicy\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\njks@cs.stanford.edu in order to arbitrarily transform an object while holding it."}},"76edfa22133b4d76bfb7c067a207e439":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77fa0ccf55d743bfa29b9e1866d837b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90a1927c45a14d20baa3b0f80bd5beae","placeholder":"​","style":"IPY_MODEL_0dcb94d7c5ab4f46b2a58bfd52a3b264","value":"Article Tractor-Robot Cooperation: A Heterogeneous Leader-Follower Approach  El Houssein Chouaib Harik  The Norwegian Institute of Bioeconomy Research (NIBIO), Center for Precision Agriculture, Nylinna 226, 2849 Kapp, Norway; elhousseinchouaib.harik@nibio.no  Abstract: In this paper, we investigated the idea of including mobile robots as complementary machinery to tractors in an agricultural context. The main idea is not to replace the human farmer, but to augment his/her capabilities by deploying mobile robots as assistants in ﬁeld operations. The scheme is based on a leader–follower approach. The manned tractor is used as a leader, which will be taken as a reference point for a follower. The follower then takes the position of the leader as a target, and follows it in an autonomous manner. This will allow the farmer to multiply the working width by the number of mobile robots deployed during ﬁeld operations. In this paper, we present a detailed description of the system, the theoretical aspect that allows the robot to autonomously follow the tractor, in addition to the different experimental steps that allowed us to test the system in the ﬁeld to assess the robustness of the proposed scheme.  Keywords: precision agriculture; agricultural robots; leader–follower navigation; multi-vehicle operations  1. Introduction  The agricultural sector is facing an ever-growing pressure to produce enough food for an increasing population, while maintaining a low level of environmental impact. The combination of both goals necessitates the inclusion of the latest advances in remotesensing techniques to collect the data as well as the latest developments in agricultural machinery to mitigate the problems that the world is facing at present regarding having a sufﬁcient food supply for everyone. Adding to this, the aging population in the agricultural sector is another factor that increases the need to look for newer alternatives to the conventional practices.  Robotics and artiﬁcial intelligent (AI) systems have contributed to the revolution of industrial processes for decades; however, the agricultural sector is still lagging behind, although it is a vital sector that is the foundation of human beings’ existence. The latest advances in robotics and AI should be gradually included, where these tools ﬁrst assist the farmers in their daily tasks, before completely replacing them in a farmer-free scenario. The main purpose of this is to provide a solution that can be adopted in the near future, in which the farmer is still in touch with the daily activities of the ﬁeld operations, and to work within the frame of the current legislation regarding the autonomous operations of robotic platforms, namely, the necessity of having a human supervisor that can take back control of the autonomous robot at all times.  Building upon the idea of using robots to assist farmers in their daily tasks, the cooperative nature of these type of systems needs to be addressed. Inspired mainly from nature (e.g., ants [1]), cooperation in robotic systems has attracted the attention of the mobile robotic research community in recent years, due to the great advantages that can be obtained by deploying multiple robots, where each robot can overcome the limitations of the other robots (perception, calculation abilities, payload, etc). Thus, the efﬁciency of the mission is increased without the need to have a single, complete, complex mobile robot.  Citation: Harik, E.H.C. Tractor-Robot  Cooperation: A Heterogeneous  Leader-Follower Approach. Robotics  2023, 12, 57. https://doi.org/  10.3390/robotics12020057  Academic Editor: Giulio Reina  Received: 28 February 2023  Revised: 30 March 2023  Accepted: 3 April 2023  Published: 6 April 2023  Copyright: © 2023 by the authors.  Licensee MDPI, Basel, Switzerland.  This article is an open access article  distributed under  the terms and  conditions of the Creative Commons  Attribution (CC BY) license (https://  creativecommons.org/licenses/by/  4.0/).  Robotics 2023, 12, 57. https://doi.org/10.3390/robotics12020057  https://www.mdpi.com/journal/robotics  robotics\f"}},"7b535913a4d54750a724b3c4d4bc98e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb269f5fa69641fcb6bbe00d47b088c5","placeholder":"​","style":"IPY_MODEL_881af9e5440947f2ad10ca6973d4e31b","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation Shenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2 Abstract— The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with theabilitytomanipulateobjectsbymeansofactivesurfacesat 0202 thefingertips.Activesurfacesareachievedbysphericalrolling fingertips with two degrees of freedom (DoF) – a pivoting motion for surface reorientation – and a continuous rolling motion for moving the object. A further DoF is in the base voN of each finger, allowing the fingers to grasp objects over a rangeofsizeandshapes.Instantaneouskinematicswasderived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through 71 imitation learning, in simulation and experimentally on the hardware. ]OR.sc[ I. INTRODUCTION In an effort to bring robots from the laboratory into real worldenvironments,researchershaveendeavoredtodevelop increasingly dexterous robots that can interact deftly with Fig.1. TheRollerGrasperV2prototypemountedonaUR-5robotarm. objects. In order for such robots to take on a wide range Three fingers, each with three degrees of freedom, can grasp and reorient of everyday tasks, they need to be capable of sophisticated anobjectusingrollingcontactwiththerubbercoatedrollers 2v99480.4002:viXra object manipulation. Many vital higher-level tasks will rely on a robot’s capability to perform in-hand manipulation by it is possible to create graspers that are highly capable but reorienting objects while maintaining the grasp. Out of all relatively simple by design. The active surface achieved by the grasping and manipulation tasks, in-hand manipulation rolling and reorientation of the spherical rollers allow the is among the ones that require the most dexterity. grasper to perform in-hand manipulation without the need A background of in-hand manipulation literature is pre- for finger gaiting. Rolling contact on the object can be sentedin[1]andamoreextensivereviewofrobothandsand viewed as a motion that continuously breaks contact with graspers is given in [2]. Common approaches to designing the object while simultaneously re-establishing contact at robotic grippers that can perform in-hand manipulation are: adjacent locations. The ability to reorient an object to any anthropomorphic hands which take advantage of intrinsic pose also lessens the need to use externally actuated degrees human dexterity, but due to the high number of degrees of freedom (e.g. actuation of the robotic arm and wrist) of freedom are complex and expensive [3] [4] [5]; under- which simplifies the control scheme. More importantly, the actuatedhandswhichpassivelyconformtoobjects,achieving spherical design of the finger tips allows for stable grasps good grasp stability, but at the cost of the controllability independentfromtherollerorientations,eliminatingtheneed needed to perform many in-hand manipulation tasks [6] [7] to analyze grasping modes for different combinations of [8] [9]; grippers with active surfaces (such as conveyors) roller orientations. whichallowfortheobjecttobemanipulatedwithoutchangLearningrobustpoliciesforin-handmanipulationhasbeen inggrasppose,butwithafixedconveyororientationlimiting a long-standing challenge in robotics due to the complexpossible motions [10] [11] [12]. ity of modelling the object and grasper contacts and the Wedevelopedanovelgrasperdesignusingarticulated,acdifficulty of controlling finger motion in long and complitivelydrivensphericalrollerslocatedatthefingertips,shown catedmanipulationsequences.DeepReinforcementLearning in Fig. 1. By incorporating continuous rotating mechanisms, (DRL) has been used to learn dexterous manipulation [13] [14]. However, learning to hold the object firmly and stably *This work has been funded, in part, by the Stanford Interdisciplinary whiletransformingtheobjectwithdeepreinforcementlearnGraduateFellowship.Detailedimplementationscanbefoundat:https:// ccrma.stanford.edu/˜shenliy/roller_grasper_v2.html ing requires many more training episodes and a carefully 1DepartmentofMechanicalEngineering,StanfordUniversity designedrewardfunction.Toovercometheseissues,weused 2StanfordArtificialIntelligenceLab(SAIL),StanfordUniversity animitationlearningbasedapproachtolearnacontrolpolicy {shenliy, lins2, clyako, agruebe2}@stanford.edu, jks@cs.stanford.edu in order to arbitrarily transform an object while holding it."}},"881af9e5440947f2ad10ca6973d4e31b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ab9652b43114b449c9d7f290f3617f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90a1927c45a14d20baa3b0f80bd5beae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9abc5294d2ed4467ab6086721a703a3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c800f0aa9e84e2bb0595c4be793e071":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4a3277258c43108f4e9b2594885367":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["yuan2020.pdf","robotics-11-00130-v2.pdf","robotics-12-00057.pdf","c9ee01935a.pdf","Abondance2020.pdf","chen2014.pdf"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"PDF File","description_tooltip":null,"disabled":false,"index":3,"layout":"IPY_MODEL_63d5d46c119f49b6a8f7bcce43b62fed","rows":3,"style":"IPY_MODEL_02f15603278243109cbc34fb413c54e9"}},"a2e20a0e837243b09c8a80835c31fec2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef0a3150aef4dedbdfc246ce7180837","placeholder":"​","style":"IPY_MODEL_e4619e9034a84321942291241d22a996","value":"2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China In-Hand Precise Twisting and Positioning by a Novel Dexterous Robotic Gripper for Industrial High-Speed Assembly Fei Chen, Member, IEEE, Ferdinando Cannella, Member, IEEE, Carlo Canali, Traveler Hauptman, Giuseppe Sofia, and Darwin Caldwell, Fellow, IEEE Abstract—Inelectronicmanufacturingsystem,thedesignof the robotic hand with sufficient dexterity and configuration is important for the successful accomplishment of the assembly task.Duetothegrowingdemandfromhigh-mixmanufacturing industry,itisdifficultforthetraditionalrobottograspalarge numberofassemblypartsortoolshavingcylindershapeswith correctpostures.Inthisresearch,anoveljawlikegripperwith human-sizedanthropomorphicfeaturesisdesignedforin-hand precisepositioningandtwistingonline.Itretainsthesimplicity featureoftraditionalindustrialgrippersanddexterityfeatures ofdexterousgrippers.Itcanapplyaconstantgrippingforceon assemblypartsandperformsreliabletwistingmovementwithin limitedtimetomeettheindustrialrequirements.Manipulating severalcylindricalassemblypartsbyrobot,asanexperimental Fig.1. AssemblyscenariointhisresearchunderAUTORECONproject case in this paper, is studied to evaluate its performance. [4]. The objective of AUTORECON project is to design a manufacturing The effectiveness of proposed gripper design and mechanical system with reconfigurable robotic manipulator under the well controlled analysisisprovedbythesimulationandexperimentalresults. information flow. To design several reconfigurable robotic hands suitable forindustrialimplementationisoneofitstasks. I. INTRODUCTION During the past tens of year, the development in manudoes.Duringthepastyearsofdevelopmentinroboticmanipfacturing industry has been divided into three main streams: ulators,nevertheless,thebasicappearanceofthemanipulator Massive Production, Medium Production and Small produchasseldomchanged,anditisalsodifficultontheotherhand tion. Small production, usually fully using robots, cannot tomodifythebasicarchitectureofrobots.Therefore,people keep in step with the growing social demanding for Hightend to improve the capacity of robots by designing various Mix, Low-Volume manufacturing. For the manufacturing functional end-effectors (hands) for robots. fully with human workers, the labor cost is also increasing In order to meet industrial application requirements, the rapidly. When addressing this problem, it is important to robotichandsmustbeinexpensive,compact,lowweightand build more flexible systems to improve the dexterity and robust.Italsomustbecapableofperformingsimplegrasping reconfigurability of current manufacturing system by conand manipulation tasks, such as precision manipulation, insideringcombiningandcoordinatingtheabovetworespects, handgrasptransitions,andsufficientlygeneraltomanipulate considering their trade-off and improving the overall asdifferent objects and tools. Up to present, most robotic sembly effectiveness and efficiency [1]. From our research, hands in both industrial and academic worlds are either few if we can provide the robot with sufficient flexibility in actuators powered jaws, or simplified human hand shape reconfiguration, it can help the factory boosting the product likedmulti-fingeredhandsforcertaingraspingpatterns.Lots quality and meanwhile reducing the cost [2]. of researchers have already paid much attention to develop Currently in robotic assembly cell for flexible manufacsuch functional robotic end-effectors in the past 25 years. A turing, there still remain many unsolved issues for robots. robotic gripper could be of two fingers, like a jaw [3] with One is that the robot cannot work efficiently in dealing twofingersinourpreviousresearch,threefingers[5]orfour with assembly parts with complicated shapes. They often fingers [6] or even more, the same with human’s hand [7]. rely on external sensor systems to help with the assembly work [3]. On the other side, human workers are skilled in Parallel manipulator [8] has been already successfully performingcomplicatedtasksusingtheirhands.Inthiscase, implementedinindustry.Theycanperformanddemonstrate it is essential that the conventional robotic manipulator is pick and place operations in really fast speed with high abletoperformcomplicatedmanipulationlikehumanworker reliability [9]. Meanwhile, it is much cheaper and simpler than serial manipulators. It is widely adopted in high speed, high-accuracy positioning within only limited workspace, Fei Chen, Ferdinando Cannella, Carlo Canali, Traveler Hauptman, GiuseppeSofia,DarwinCaldwellarewithintheDepartmentofAdvanced such as food packing and electronic parts placing. Robotics, Istituto Italiano di Tecnologia, Italy, 16163, E-mail: {fei.chen, Another novel universal grippers is developed, which ferdinando.cannella, carlo.canali, traveler.hauptman, giuseppe.sofia, darwin.caldwell}@iit.it. is able to pick up unfamiliar objects of widely varying 978-1-4799-3685-4/14/$31.00 ©2014 IEEE 270"}},"a333fc9847dc439a8b42d541cf57b845":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"10%"}},"a40ae8a807154111884513aa5622418a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a83c68ee145245f28424f322bebb530d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8dc3faaeb2d4d689c1cac40f4a1a0d8","placeholder":"​","style":"IPY_MODEL_e607bf085b1648189880b0ceedb45643","value":"Article Tractor-Robot Cooperation: A Heterogeneous Leader-Follower Approach  El Houssein Chouaib Harik  The Norwegian Institute of Bioeconomy Research (NIBIO), Center for Precision Agriculture, Nylinna 226, 2849 Kapp, Norway; elhousseinchouaib.harik@nibio.no  Abstract: In this paper, we investigated the idea of including mobile robots as complementary machinery to tractors in an agricultural context. The main idea is not to replace the human farmer, but to augment his/her capabilities by deploying mobile robots as assistants in ﬁeld operations. The scheme is based on a leader–follower approach. The manned tractor is used as a leader, which will be taken as a reference point for a follower. The follower then takes the position of the leader as a target, and follows it in an autonomous manner. This will allow the farmer to multiply the working width by the number of mobile robots deployed during ﬁeld operations. In this paper, we present a detailed description of the system, the theoretical aspect that allows the robot to autonomously follow the tractor, in addition to the different experimental steps that allowed us to test the system in the ﬁeld to assess the robustness of the proposed scheme.  Keywords: precision agriculture; agricultural robots; leader–follower navigation; multi-vehicle operations  1. Introduction  The agricultural sector is facing an ever-growing pressure to produce enough food for an increasing population, while maintaining a low level of environmental impact. The combination of both goals necessitates the inclusion of the latest advances in remotesensing techniques to collect the data as well as the latest developments in agricultural machinery to mitigate the problems that the world is facing at present regarding having a sufﬁcient food supply for everyone. Adding to this, the aging population in the agricultural sector is another factor that increases the need to look for newer alternatives to the conventional practices.  Robotics and artiﬁcial intelligent (AI) systems have contributed to the revolution of industrial processes for decades; however, the agricultural sector is still lagging behind, although it is a vital sector that is the foundation of human beings’ existence. The latest advances in robotics and AI should be gradually included, where these tools ﬁrst assist the farmers in their daily tasks, before completely replacing them in a farmer-free scenario. The main purpose of this is to provide a solution that can be adopted in the near future, in which the farmer is still in touch with the daily activities of the ﬁeld operations, and to work within the frame of the current legislation regarding the autonomous operations of robotic platforms, namely, the necessity of having a human supervisor that can take back control of the autonomous robot at all times.  Building upon the idea of using robots to assist farmers in their daily tasks, the cooperative nature of these type of systems needs to be addressed. Inspired mainly from nature (e.g., ants [1]), cooperation in robotic systems has attracted the attention of the mobile robotic research community in recent years, due to the great advantages that can be obtained by deploying multiple robots, where each robot can overcome the limitations of the other robots (perception, calculation abilities, payload, etc). Thus, the efﬁciency of the mission is increased without the need to have a single, complete, complex mobile robot.  Citation: Harik, E.H.C. Tractor-Robot  Cooperation: A Heterogeneous  Leader-Follower Approach. Robotics  2023, 12, 57. https://doi.org/  10.3390/robotics12020057  Academic Editor: Giulio Reina  Received: 28 February 2023  Revised: 30 March 2023  Accepted: 3 April 2023  Published: 6 April 2023  Copyright: © 2023 by the authors.  Licensee MDPI, Basel, Switzerland.  This article is an open access article  distributed under  the terms and  conditions of the Creative Commons  Attribution (CC BY) license (https://  creativecommons.org/licenses/by/  4.0/).  Robotics 2023, 12, 57. https://doi.org/10.3390/robotics12020057  https://www.mdpi.com/journal/robotics  robotics\f"}},"adaf3721175f4a0ab7b684181dcbaa78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["text","metadata"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"Options","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_f0ebc717e73b43c3a52967b50f5aff3d","rows":3,"style":"IPY_MODEL_4c8dc223d141490ca29279d9a3e4385a"}},"afe464ef307d49daa3d9c86fc8a1d8f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20%"}},"afef6760867641de9d3c3f47e4ff54e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8a44a00a8bd4d5da2369228e8d89aa7","placeholder":"​","style":"IPY_MODEL_e08db4e997d34da89c579c97e672eeea","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\nthe ability to manipulate objects by means of active surfaces at\nthe ﬁngertips. Active surfaces are achieved by spherical rolling\nﬁngertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nof each ﬁnger, allowing the ﬁngers to grasp objects over a\nrange of size and shapes. Instantaneous kinematics was derived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\nimitation learning, in simulation and experimentally on the\nhardware.\nI. INTRODUCTION\nIn an effort to bring robots from the laboratory into real\nworld environments, researchers have endeavored to develop\nincreasingly dexterous robots that can interact deftly with\nobjects. In order for such robots to take on a wide range\nof everyday tasks, they need to be capable of sophisticated\nobject manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by\nreorienting objects while maintaining the grasp. Out of all\nthe grasping and manipulation tasks, in-hand manipulation\nis among the ones that require the most dexterity.\nA background of in-hand manipulation literature is pre-\nsented in [1] and a more extensive review of robot hands and\ngraspers is given in [2]. Common approaches to designing\nrobotic grippers that can perform in-hand manipulation are:\nanthropomorphic hands which take advantage of intrinsic\nhuman dexterity, but due to the high number of degrees\nof freedom are complex and expensive [3] [4] [5]; under-\nactuated hands which passively conform to objects, achieving\ngood grasp stability, but at the cost of the controllability\nneeded to perform many in-hand manipulation tasks [6] [7]\n[8] [9]; grippers with active surfaces (such as conveyors)\nwhich allow for the object to be manipulated without chang-\ning grasp pose, but with a ﬁxed conveyor orientation limiting\npossible motions [10] [11] [12].\nWe developed a novel grasper design using articulated, ac-\ntively driven spherical rollers located at the ﬁngertips, shown\nin Fig. 1. By incorporating continuous rotating mechanisms,\n*This work has been funded, in part, by the Stanford Interdisciplinary\nGraduate Fellowship. Detailed implementations can be found at: https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html\n1Department of Mechanical Engineering, Stanford University\n2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\njks@cs.stanford.edu\nFig. 1.\nThe Roller Grasper V2 prototype mounted on a UR-5 robot arm.\nThree ﬁngers, each with three degrees of freedom, can grasp and reorient\nan object using rolling contact with the rubber coated rollers\nit is possible to create graspers that are highly capable but\nrelatively simple by design. The active surface achieved by\nrolling and reorientation of the spherical rollers allow the\ngrasper to perform in-hand manipulation without the need\nfor ﬁnger gaiting. Rolling contact on the object can be\nviewed as a motion that continuously breaks contact with\nthe object while simultaneously re-establishing contact at\nadjacent locations. The ability to reorient an object to any\npose also lessens the need to use externally actuated degrees\nof freedom (e.g. actuation of the robotic arm and wrist)\nwhich simpliﬁes the control scheme. More importantly, the\nspherical design of the ﬁnger tips allows for stable grasps\nindependent from the roller orientations, eliminating the need\nto analyze grasping modes for different combinations of\nroller orientations.\nLearning robust policies for in-hand manipulation has been\na long-standing challenge in robotics due to the complex-\nity of modelling the object and grasper contacts and the\ndifﬁculty of controlling ﬁnger motion in long and compli-\ncated manipulation sequences. Deep Reinforcement Learning\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object ﬁrmly and stably\nwhile transforming the object with deep reinforcement learn-\ning requires many more training episodes and a carefully\ndesigned reward function. To overcome these issues, we used\nan imitation learning based approach to learn a control policy\nin order to arbitrarily transform an object while holding it.\n"}},"b4d734a3156e49608227bd577bbbb411":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b760301e8bd4e518018f228d6e68a67","placeholder":"​","style":"IPY_MODEL_9abc5294d2ed4467ab6086721a703a3c","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation  Shenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2  0 2 0 2  v o N 7 1  ]  O R . s c [  2 v 9 9 4 8 0 . 4 0 0 2 : v i X r a  Abstract— The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the ﬁngertips. Active surfaces are achieved by spherical rolling ﬁngertips with two degrees of freedom (DoF) – a pivoting motion for surface reorientation – and a continuous rolling motion for moving the object. A further DoF is in the base of each ﬁnger, allowing the ﬁngers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware.  I. INTRODUCTION  In an effort to bring robots from the laboratory into real world environments, researchers have endeavored to develop increasingly dexterous robots that can interact deftly with objects. In order for such robots to take on a wide range of everyday tasks, they need to be capable of sophisticated object manipulation. Many vital higher-level tasks will rely on a robot’s capability to perform in-hand manipulation by reorienting objects while maintaining the grasp. Out of all the grasping and manipulation tasks, in-hand manipulation is among the ones that require the most dexterity.  A background of in-hand manipulation literature is presented in [1] and a more extensive review of robot hands and graspers is given in [2]. Common approaches to designing robotic grippers that can perform in-hand manipulation are: anthropomorphic hands which take advantage of intrinsic human dexterity, but due to the high number of degrees of freedom are complex and expensive [3] [4] [5]; underactuated hands which passively conform to objects, achieving good grasp stability, but at the cost of the controllability needed to perform many in-hand manipulation tasks [6] [7] [8] [9]; grippers with active surfaces (such as conveyors) which allow for the object to be manipulated without changing grasp pose, but with a ﬁxed conveyor orientation limiting possible motions [10] [11] [12].  We developed a novel grasper design using articulated, actively driven spherical rollers located at the ﬁngertips, shown in Fig. 1. By incorporating continuous rotating mechanisms,  *This work has been funded, in part, by the Stanford Interdisciplinary Graduate Fellowship. Detailed implementations can be found at: https:// ccrma.stanford.edu/˜shenliy/roller_grasper_v2.html  1Department of Mechanical Engineering, Stanford University 2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University {shenliy, lins2, clyako, agruebe2}@stanford.edu,  jks@cs.stanford.edu  Fig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm. Three ﬁngers, each with three degrees of freedom, can grasp and reorient an object using rolling contact with the rubber coated rollers  it is possible to create graspers that are highly capable but relatively simple by design. The active surface achieved by rolling and reorientation of the spherical rollers allow the grasper to perform in-hand manipulation without the need for ﬁnger gaiting. Rolling contact on the object can be viewed as a motion that continuously breaks contact with the object while simultaneously re-establishing contact at adjacent locations. The ability to reorient an object to any pose also lessens the need to use externally actuated degrees of freedom (e.g. actuation of the robotic arm and wrist) which simpliﬁes the control scheme. More importantly, the spherical design of the ﬁnger tips allows for stable grasps independent from the roller orientations, eliminating the need to analyze grasping modes for different combinations of roller orientations.  Learning robust policies for in-hand manipulation has been a long-standing challenge in robotics due to the complexity of modelling the object and grasper contacts and the difﬁculty of controlling ﬁnger motion in long and complicated manipulation sequences. Deep Reinforcement Learning (DRL) has been used to learn dexterous manipulation [13] [14]. However, learning to hold the object ﬁrmly and stably while transforming the object with deep reinforcement learning requires many more training episodes and a carefully designed reward function. To overcome these issues, we used an imitation learning based approach to learn a control policy in order to arbitrarily transform an object while holding it.              \f"}},"b5aa942ffb914b799de1096438f893f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbb750479928468290283e289144fc16","placeholder":"​","style":"IPY_MODEL_e8e57a79c0624721b0bf2de2a0888744","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation\n\nShenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2\n\n0\n2\n0\n2\n\nv\no\nN\n7\n1\n\n]\n\nO\nR\n.\ns\nc\n[\n\n2\nv\n9\n9\n4\n8\n0\n.\n4\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract— The ability to perform in-hand manipulation\nstill remains an unsolved problem; having this capability\nwould allow robots to perform sophisticated tasks requiring\nrepositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with\nthe ability to manipulate objects by means of active surfaces at\nthe ﬁngertips. Active surfaces are achieved by spherical rolling\nﬁngertips with two degrees of freedom (DoF) – a pivoting\nmotion for surface reorientation – and a continuous rolling\nmotion for moving the object. A further DoF is in the base\nof each ﬁnger, allowing the ﬁngers to grasp objects over a\nrange of size and shapes. Instantaneous kinematics was derived\nand objects were successfully manipulated both with a custom\nhandcrafted control scheme as well as one learned through\nimitation learning,\nin simulation and experimentally on the\nhardware.\n\nI. INTRODUCTION\n\nIn an effort to bring robots from the laboratory into real\nworld environments, researchers have endeavored to develop\nincreasingly dexterous robots that can interact deftly with\nobjects. In order for such robots to take on a wide range\nof everyday tasks, they need to be capable of sophisticated\nobject manipulation. Many vital higher-level tasks will rely\non a robot’s capability to perform in-hand manipulation by\nreorienting objects while maintaining the grasp. Out of all\nthe grasping and manipulation tasks, in-hand manipulation\nis among the ones that require the most dexterity.\n\nA background of in-hand manipulation literature is pre-\nsented in [1] and a more extensive review of robot hands and\ngraspers is given in [2]. Common approaches to designing\nrobotic grippers that can perform in-hand manipulation are:\nanthropomorphic hands which take advantage of intrinsic\nhuman dexterity, but due to the high number of degrees\nof freedom are complex and expensive [3] [4] [5]; under-\nactuated hands which passively conform to objects, achieving\ngood grasp stability, but at the cost of the controllability\nneeded to perform many in-hand manipulation tasks [6] [7]\n[8] [9]; grippers with active surfaces (such as conveyors)\nwhich allow for the object to be manipulated without chang-\ning grasp pose, but with a ﬁxed conveyor orientation limiting\npossible motions [10] [11] [12].\n\nWe developed a novel grasper design using articulated, ac-\ntively driven spherical rollers located at the ﬁngertips, shown\nin Fig. 1. By incorporating continuous rotating mechanisms,\n\n*This work has been funded, in part, by the Stanford Interdisciplinary\nGraduate Fellowship. Detailed implementations can be found at: https://\nccrma.stanford.edu/˜shenliy/roller_grasper_v2.html\n\n1Department of Mechanical Engineering, Stanford University\n2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University\n{shenliy, lins2, clyako, agruebe2}@stanford.edu,\n\njks@cs.stanford.edu\n\nFig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm.\nThree ﬁngers, each with three degrees of freedom, can grasp and reorient\nan object using rolling contact with the rubber coated rollers\n\nit is possible to create graspers that are highly capable but\nrelatively simple by design. The active surface achieved by\nrolling and reorientation of the spherical rollers allow the\ngrasper to perform in-hand manipulation without the need\nfor ﬁnger gaiting. Rolling contact on the object can be\nviewed as a motion that continuously breaks contact with\nthe object while simultaneously re-establishing contact at\nadjacent locations. The ability to reorient an object to any\npose also lessens the need to use externally actuated degrees\nof freedom (e.g. actuation of the robotic arm and wrist)\nwhich simpliﬁes the control scheme. More importantly, the\nspherical design of the ﬁnger tips allows for stable grasps\nindependent from the roller orientations, eliminating the need\nto analyze grasping modes for different combinations of\nroller orientations.\n\nLearning robust policies for in-hand manipulation has been\na long-standing challenge in robotics due to the complex-\nity of modelling the object and grasper contacts and the\ndifﬁculty of controlling ﬁnger motion in long and compli-\ncated manipulation sequences. Deep Reinforcement Learning\n(DRL) has been used to learn dexterous manipulation [13]\n[14]. However, learning to hold the object ﬁrmly and stably\nwhile transforming the object with deep reinforcement learn-\ning requires many more training episodes and a carefully\ndesigned reward function. To overcome these issues, we used\nan imitation learning based approach to learn a control policy\nin order to arbitrarily transform an object while holding it.\n\n \n \n \n \n \n \n\f"}},"bb269f5fa69641fcb6bbe00d47b088c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c09b8528c59e46fbb727c5abc0ff3698":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"10%"}},"c0f87af0cfb54a6895af214cd76d7701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"SelectModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SelectModel","_options_labels":["1","2","3","4","5","6","7"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"SelectView","description":"Page","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_a333fc9847dc439a8b42d541cf57b845","rows":3,"style":"IPY_MODEL_d60a150880164d45b88376049df901e1"}},"c495ff0465e34095bc5f1a2f6605f36e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c578cdbf64b74df3ba9fa96405e7064a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c871dbbb4b4d471e99ad921c33647084":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3148954ca46545cf956d71a2c30120a0","placeholder":"​","style":"IPY_MODEL_4748ad0315aa48ef874180cbf23840e9","value":"2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China  978-1-4799-3685-4/14/$31.00 ©2014 IEEE  270  In-HandPreciseTwistingandPositioningbyaNovelDexterousRoboticGripperforIndustrialHigh-SpeedAssemblyFeiChen,Member,IEEE,FerdinandoCannella,Member,IEEE,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,andDarwinCaldwell,Fellow,IEEEAbstract—Inelectronicmanufacturingsystem,thedesignoftherobotichandwithsufﬁcientdexterityandconﬁgurationisimportantforthesuccessfulaccomplishmentoftheassemblytask.Duetothegrowingdemandfromhigh-mixmanufacturingindustry,itisdifﬁcultforthetraditionalrobottograspalargenumberofassemblypartsortoolshavingcylindershapeswithcorrectpostures.Inthisresearch,anoveljawlikegripperwithhuman-sizedanthropomorphicfeaturesisdesignedforin-handprecisepositioningandtwistingonline.Itretainsthesimplicityfeatureoftraditionalindustrialgrippersanddexterityfeaturesofdexterousgrippers.Itcanapplyaconstantgrippingforceonassemblypartsandperformsreliabletwistingmovementwithinlimitedtimetomeettheindustrialrequirements.Manipulatingseveralcylindricalassemblypartsbyrobot,asanexperimentalcaseinthispaper,isstudiedtoevaluateitsperformance.Theeffectivenessofproposedgripperdesignandmechanicalanalysisisprovedbythesimulationandexperimentalresults.I.INTRODUCTIONDuringthepasttensofyear,thedevelopmentinmanu-facturingindustryhasbeendividedintothreemainstreams:MassiveProduction,MediumProductionandSmallproduc-tion.Smallproduction,usuallyfullyusingrobots,cannotkeepinstepwiththegrowingsocialdemandingforHigh-Mix,Low-Volumemanufacturing.Forthemanufacturingfullywithhumanworkers,thelaborcostisalsoincreasingrapidly.Whenaddressingthisproblem,itisimportanttobuildmoreﬂexiblesystemstoimprovethedexterityandreconﬁgurabilityofcurrentmanufacturingsystembycon-sideringcombiningandcoordinatingtheabovetworespects,consideringtheirtrade-offandimprovingtheoverallas-semblyeffectivenessandefﬁciency[1].Fromourresearch,ifwecanprovidetherobotwithsufﬁcientﬂexibilityinreconﬁguration,itcanhelpthefactoryboostingtheproductqualityandmeanwhilereducingthecost[2].Currentlyinroboticassemblycellforﬂexiblemanufac-turing,therestillremainmanyunsolvedissuesforrobots.Oneisthattherobotcannotworkefﬁcientlyindealingwithassemblypartswithcomplicatedshapes.Theyoftenrelyonexternalsensorsystemstohelpwiththeassemblywork[3].Ontheotherside,humanworkersareskilledinperformingcomplicatedtasksusingtheirhands.Inthiscase,itisessentialthattheconventionalroboticmanipulatorisabletoperformcomplicatedmanipulationlikehumanworkerFeiChen,FerdinandoCannella,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,DarwinCaldwellarewithintheDepartmentofAdvancedRobotics,IstitutoItalianodiTecnologia,Italy,16163,E-mail:{fei.chen,ferdinando.cannella,carlo.canali,traveler.hauptman,giuseppe.soﬁa,dar-win.caldwell}@iit.it.Fig.1.AssemblyscenariointhisresearchunderAUTORECONproject[4].TheobjectiveofAUTORECONprojectistodesignamanufacturingsystemwithreconﬁgurableroboticmanipulatorunderthewellcontrolledinformationﬂow.Todesignseveralreconﬁgurablerobotichandssuitableforindustrialimplementationisoneofitstasks.does.Duringthepastyearsofdevelopmentinroboticmanip-ulators,nevertheless,thebasicappearanceofthemanipulatorhasseldomchanged,anditisalsodifﬁcultontheotherhandtomodifythebasicarchitectureofrobots.Therefore,peopletendtoimprovethecapacityofrobotsbydesigningvariousfunctionalend-effectors(hands)forrobots.Inordertomeetindustrialapplicationrequirements,therobotichandsmustbeinexpensive,compact,lowweightandrobust.Italsomustbecapableofperformingsimplegraspingandmanipulationtasks,suchasprecisionmanipulation,in-handgrasptransitions,andsufﬁcientlygeneraltomanipulatedifferentobjectsandtools.Uptopresent,mostrobotichandsinbothindustrialandacademicworldsareeitherfewactuatorspoweredjaws,orsimpliﬁedhumanhandshapelikedmulti-ﬁngeredhandsforcertaingraspingpatterns.Lotsofresearchershavealreadypaidmuchattentiontodevelopsuchfunctionalroboticend-effectorsinthepast25years.Aroboticgrippercouldbeoftwoﬁngers,likeajaw[3]withtwoﬁngersinourpreviousresearch,threeﬁngers[5]orfourﬁngers[6]orevenmore,thesamewithhuman’shand[7].Parallelmanipulator[8]hasbeenalreadysuccessfullyimplementedinindustry.Theycanperformanddemonstratepickandplaceoperationsinreallyfastspeedwithhighreliability[9].Meanwhile,itismuchcheaperandsimplerthanserialmanipulators.Itiswidelyadoptedinhighspeed,high-accuracypositioningwithinonlylimitedworkspace,suchasfoodpackingandelectronicpartsplacing.Anothernoveluniversalgrippersisdeveloped,whichisabletopickupunfamiliarobjectsofwidelyvarying\f"}},"c8dc3faaeb2d4d689c1cac40f4a1a0d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbb750479928468290283e289144fc16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbdb35f562ee44e4a347b95076e75a7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbef93357efb4e01ab217f87e9e6dd9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd9ecb0f57844d6da5bf63fd16d6e059":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d36ce211a6224d60b35652243e5f32ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd664760b274978b00516d409530803","placeholder":"​","style":"IPY_MODEL_41c3f5d7e11a4ff5af6ee524713f7af4","value":"In-Hand Precise Twisting and Positioning by a Novel Dexterous Robotic Gripper for Industrial High-Speed Assembly Fei Chen, Member, IEEE, Ferdinando Cannella, Member, IEEE, Carlo Canali, Traveler Hauptman, Giuseppe Soﬁa, and Darwin Caldwell, Fellow, IEEE Abstract— In electronic manufacturing system, the design of the robotic hand with sufﬁcient dexterity and conﬁguration is important for the successful accomplishment of the assembly task. Due to the growing demand from high-mix manufacturing industry, it is difﬁcult for the traditional robot to grasp a large number of assembly parts or tools having cylinder shapes with correct postures. In this research, a novel jaw like gripper with human-sized anthropomorphic features is designed for in-hand precise positioning and twisting online. It retains the simplicity feature of traditional industrial grippers and dexterity features of dexterous grippers. It can apply a constant gripping force on assembly parts and performs reliable twisting movement within limited time to meet the industrial requirements. Manipulating several cylindrical assembly parts by robot, as an experimental case in this paper, is studied to evaluate its performance. The effectiveness of proposed gripper design and mechanical analysis is proved by the simulation and experimental results. I. INTRODUCTION During the past tens of year, the development in manufacturing industry has been divided into three main streams: Massive Production, Medium Production and Small production. Small production, usually fully using robots, cannot keep in step with the growing social demanding for HighMix, Low-Volume manufacturing. For the manufacturing fully with human workers, the labor cost is also increasing rapidly. When addressing this problem, it is important to build more ﬂexible systems to improve the dexterity and reconﬁgurability of current manufacturing system by considering combining and coordinating the above two respects, considering their trade-off and improving the overall assembly effectiveness and efﬁciency [1]. From our research, if we can provide the robot with sufﬁcient ﬂexibility in reconﬁguration, it can help the factory boosting the product quality and meanwhile reducing the cost [2]. Currently in robotic assembly cell for ﬂexible manufacturing, there still remain many unsolved issues for robots. One is that the robot cannot work efﬁciently in dealing with assembly parts with complicated shapes. They often rely on external sensor systems to help with the assembly work [3]. On the other side, human workers are skilled in performing complicated tasks using their hands. In this case, it is essential that the conventional robotic manipulator is able to perform complicated manipulation like human worker Fei Chen, Ferdinando Cannella, Carlo Canali, Traveler Hauptman, Giuseppe Soﬁa, Darwin Caldwell are within the Department of Advanced Robotics, Istituto Italiano di Tecnologia, Italy, 16163, E-mail: {fei.chen, ferdinando.cannella, carlo.canali, traveler.hauptman, giuseppe.soﬁa, darwin.caldwell}@iit.it. Fig. 1. Assembly scenario in this research under AUTORECON project [4]. The objective of AUTORECON project is to design a manufacturing system with reconﬁgurable robotic manipulator under the well controlled information ﬂow. To design several reconﬁgurable robotic hands suitable for industrial implementation is one of its tasks. does. During the past years of development in robotic manipulators, nevertheless, the basic appearance of the manipulator has seldom changed, and it is also difﬁcult on the other hand to modify the basic architecture of robots. Therefore, people tend to improve the capacity of robots by designing various functional end-effectors (hands) for robots. In order to meet industrial application requirements, the robotic hands must be inexpensive, compact, low weight and robust. It also must be capable of performing simple grasping and manipulation tasks, such as precision manipulation, inhand grasp transitions, and sufﬁciently general to manipulate different objects and tools. Up to present, most robotic hands in both industrial and academic worlds are either few actuators powered jaws, or simpliﬁed human hand shape liked multi-ﬁngered hands for certain grasping patterns. Lots of researchers have already paid much attention to develop such functional robotic end-effectors in the past 25 years. A robotic gripper could be of two ﬁngers, like a jaw [3] with two ﬁngers in our previous research, three ﬁngers [5] or four ﬁngers [6] or even more, the same with human’s hand [7]. Parallel manipulator [8] has been already successfully implemented in industry. They can perform and demonstrate pick and place operations in really fast speed with high reliability [9]. Meanwhile, it is much cheaper and simpler than serial manipulators. It is widely adopted in high speed, high-accuracy positioning within only limited workspace, such as food packing and electronic parts placing. Another novel universal grippers is developed, which is able to pick up unfamiliar objects of widely varying 2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China 978-1-4799-3685-4/14/$31.00 ©2014 IEEE 270 "}},"d40983429d9c4c948c965d173188b93f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5bddb4874c74c079dff8ab0aea16cec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d60a150880164d45b88376049df901e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8a44a00a8bd4d5da2369228e8d89aa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba0091ec9574024a76ea441edf1e712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54bc3491b078400fa79bc6648bdf1d87","placeholder":"​","style":"IPY_MODEL_1902358cf6064e46abe5a15cfef28d45","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation Shenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2 Abstract— The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the ﬁngertips. Active surfaces are achieved by spherical rolling ﬁngertips with two degrees of freedom (DoF) – a pivoting motion for surface reorientation – and a continuous rolling motion for moving the object. A further DoF is in the base of each ﬁnger, allowing the ﬁngers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware. I. INTRODUCTION In an effort to bring robots from the laboratory into real world environments, researchers have endeavored to develop increasingly dexterous robots that can interact deftly with objects. In order for such robots to take on a wide range of everyday tasks, they need to be capable of sophisticated object manipulation. Many vital higher-level tasks will rely on a robot’s capability to perform in-hand manipulation by reorienting objects while maintaining the grasp. Out of all the grasping and manipulation tasks, in-hand manipulation is among the ones that require the most dexterity. A background of in-hand manipulation literature is presented in [1] and a more extensive review of robot hands and graspers is given in [2]. Common approaches to designing robotic grippers that can perform in-hand manipulation are: anthropomorphic hands which take advantage of intrinsic human dexterity, but due to the high number of degrees of freedom are complex and expensive [3] [4] [5]; underactuated hands which passively conform to objects, achieving good grasp stability, but at the cost of the controllability needed to perform many in-hand manipulation tasks [6] [7] [8] [9]; grippers with active surfaces (such as conveyors) which allow for the object to be manipulated without changing grasp pose, but with a ﬁxed conveyor orientation limiting possible motions [10] [11] [12]. We developed a novel grasper design using articulated, actively driven spherical rollers located at the ﬁngertips, shown in Fig. 1. By incorporating continuous rotating mechanisms, *This work has been funded, in part, by the Stanford Interdisciplinary Graduate Fellowship. Detailed implementations can be found at: https:// ccrma.stanford.edu/˜shenliy/roller_grasper_v2.html 1Department of Mechanical Engineering, Stanford University 2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University {shenliy, lins2, clyako, agruebe2}@stanford.edu, jks@cs.stanford.edu Fig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm. Three ﬁngers, each with three degrees of freedom, can grasp and reorient an object using rolling contact with the rubber coated rollers it is possible to create graspers that are highly capable but relatively simple by design. The active surface achieved by rolling and reorientation of the spherical rollers allow the grasper to perform in-hand manipulation without the need for ﬁnger gaiting. Rolling contact on the object can be viewed as a motion that continuously breaks contact with the object while simultaneously re-establishing contact at adjacent locations. The ability to reorient an object to any pose also lessens the need to use externally actuated degrees of freedom (e.g. actuation of the robotic arm and wrist) which simpliﬁes the control scheme. More importantly, the spherical design of the ﬁnger tips allows for stable grasps independent from the roller orientations, eliminating the need to analyze grasping modes for different combinations of roller orientations. Learning robust policies for in-hand manipulation has been a long-standing challenge in robotics due to the complexity of modelling the object and grasper contacts and the difﬁculty of controlling ﬁnger motion in long and complicated manipulation sequences. Deep Reinforcement Learning (DRL) has been used to learn dexterous manipulation [13] [14]. However, learning to hold the object ﬁrmly and stably while transforming the object with deep reinforcement learning requires many more training episodes and a carefully designed reward function. To overcome these issues, we used an imitation learning based approach to learn a control policy in order to arbitrarily transform an object while holding it. "}},"dbd664760b274978b00516d409530803":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf557c272df4329afb683984b20d5ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9c61b7c0ab4b1cb4cb28427e20de23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_588831bba5c04513bca80db9dea18dc5","placeholder":"​","style":"IPY_MODEL_cd9ecb0f57844d6da5bf63fd16d6e059","value":"Article Obstacles Avoidance for Mobile Robot Using Type-2 Fuzzy Logic Controller  Mohammad Al-Mallah 1, Mohammad Ali 2 and Mustafa Al-Khawaldeh 1,*  1 Department of Mechatronics Engineering, Philadelphia University, P.O. Box 1, Amman 19392, Jordan 2 Department of Electrical Engineering, Philadelphia University, P.O. Box 1, Amman 19392, Jordan * Correspondence: malkhawaldeh@philadelphia.edu.jo  Abstract: Intelligent mobile robots need to deal with different kinds of uncertainties in order to perform their tasks, such as tracking predeﬁned paths and avoiding static and dynamic obstacles until reaching their destination. In this research, a Robotino® from Festo Company was used to reach a predeﬁned target in different scenarios, autonomously, in a static and dynamic environment. A Type-2 fuzzy logic controller was used to guide and help Robotino® reach its predeﬁned destination safely. The Robotino® collects data from the environment. The rules of the Type-2 fuzzy logic controller were built from human experience. They controlled the Robotino® movement, guiding it toward its goal by controlling its linear and angular velocities, preventing it from colliding obstacles at the same time, as well. The Takagi–Sugeno–Kang (TSK) algorithm was implemented. Real-time and simulation experimental results showed the capability and effectiveness of the proposed controller, especially in dealing with uncertainty problems.  Keywords: mobile robot; Robotino®; static and dynamic obstacle-avoidance environment; Type-2 fuzzy logic controller; wireless sensor network  Citation: Al-Mallah, M.; Ali, M.;  Al-Khawaldeh, M. Obstacles  Avoidance for Mobile Robot Using  Type-2 Fuzzy Logic Controller.  Robotics 2022, 11, 130. https://  doi.org/10.3390/robotics11060130  Received: 27 September 2022  Accepted: 8 November 2022  Published: 16 November 2022  Publisher’s Note: MDPI stays neutral  with regard to jurisdictional claims in  published maps and institutional afﬁl iations.  Copyright: © 2022 by the authors.  Licensee MDPI, Basel, Switzerland.  This article is an open access article  distributed under  the terms and  conditions of the Creative Commons  Attribution (CC BY) license (https://  creativecommons.org/licenses/by/  4.0/).  1. Introduction  Nowadays, robots are an inseparable part of our life. Robots with movement ability impose themselves through many applications, including medical facilities, hospitality, entertainment, package delivery, space, and military. Recently, mobile robots have been a controlling contributor to human development and one of the fastest growth ﬁelds of scientiﬁc research. They have displayed their abilities in helping and substituting humans in many applications with high efﬁciency [1].  The obstacle avoidance is an important feature in mobile robots that enables them to reach their destination point collision free. This necessitates providing them with a decisionmaking capability for planning their path autonomously and reacting to the hazards that may hinder their movements. However, this is no longer easily achieved by using classical control approaches without prior information available about the environment and using intelligent control [1]. Furthermore, some of the intelligent control methods cannot handle the high level of uncertainties of sensors, actuators, and environment [2].  For achieving autonomous obstacle avoidance, numerous control strategies have been developed, among which is the Type-2 fuzzy logic control. Fuzzy logic control is considered the most vastly used technique for designing controllers that manage suitable performance in many real-world applications [3]. For example, it was used to design a controller capable of introducing a safe Robotino® and tracking its predeﬁned target, as in Ref. [4]. A fuzzy logic controller with 153 fuzzy rules was utilized for controlling the Robotino® path-tracking issue, while another fuzzy logic controller with 27 fuzzy rules was applied for the Robotino® obstacle-avoidance feature, using the Sugeno fuzzy algorithm. Many real-time experiments reﬂected good abilities of the proposed controllers. Moreover, an autonomous mobile robot was designed and implemented by using a fuzzy logic controller,  Robotics 2022, 11, 130. https://doi.org/10.3390/robotics11060130  https://www.mdpi.com/journal/robotics  robotics\f"}},"de9b5f6f7d3c4473a1862cd625df223e":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_76edfa22133b4d76bfb7c067a207e439","msg_id":"","outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"141a23bbb603486aa86350566af76ed3","version_major":2,"version_minor":0},"text/plain":"HTML(value='24 | Energy Environ. Sci., 2020, 13, 24--52 This journal is © The Royal Society of Chemistry 2020 …"},"metadata":{},"output_type":"display_data"}]}},"e08db4e997d34da89c579c97e672eeea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3d1f919971b40cf8bdf48ff4ed7b7ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4619e9034a84321942291241d22a996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5cfaade046249509aec6de1860e0974":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18690d2646b54eea9affbc9349ec0051","placeholder":"​","style":"IPY_MODEL_1a783940fdfb41f4aa7b1a8392523933","value":"Design and Control of Roller Grasper V2 for In-Hand Manipulation  Shenli Yuan1,2, Lin Shao2, Connor L. Yako1,2, Alex Gruebele1, and J. Kenneth Salisbury2  0 2 0 2  v o N 7 1  ]  O R . s c [  2 v 9 9 4 8 0 . 4 0 0 2 : v i X r a  Abstract— The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the ﬁngertips. Active surfaces are achieved by spherical rolling ﬁngertips with two degrees of freedom (DoF) – a pivoting motion for surface reorientation – and a continuous rolling motion for moving the object. A further DoF is in the base of each ﬁnger, allowing the ﬁngers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware.  I. INTRODUCTION  In an effort to bring robots from the laboratory into real world environments, researchers have endeavored to develop increasingly dexterous robots that can interact deftly with objects. In order for such robots to take on a wide range of everyday tasks, they need to be capable of sophisticated object manipulation. Many vital higher-level tasks will rely on a robot’s capability to perform in-hand manipulation by reorienting objects while maintaining the grasp. Out of all the grasping and manipulation tasks, in-hand manipulation is among the ones that require the most dexterity.  A background of in-hand manipulation literature is presented in [1] and a more extensive review of robot hands and graspers is given in [2]. Common approaches to designing robotic grippers that can perform in-hand manipulation are: anthropomorphic hands which take advantage of intrinsic human dexterity, but due to the high number of degrees of freedom are complex and expensive [3] [4] [5]; underactuated hands which passively conform to objects, achieving good grasp stability, but at the cost of the controllability needed to perform many in-hand manipulation tasks [6] [7] [8] [9]; grippers with active surfaces (such as conveyors) which allow for the object to be manipulated without changing grasp pose, but with a ﬁxed conveyor orientation limiting possible motions [10] [11] [12].  We developed a novel grasper design using articulated, actively driven spherical rollers located at the ﬁngertips, shown in Fig. 1. By incorporating continuous rotating mechanisms,  *This work has been funded, in part, by the Stanford Interdisciplinary Graduate Fellowship. Detailed implementations can be found at: https:// ccrma.stanford.edu/˜shenliy/roller_grasper_v2.html  1Department of Mechanical Engineering, Stanford University 2Stanford Artiﬁcial Intelligence Lab (SAIL), Stanford University {shenliy, lins2, clyako, agruebe2}@stanford.edu,  jks@cs.stanford.edu  Fig. 1. The Roller Grasper V2 prototype mounted on a UR-5 robot arm. Three ﬁngers, each with three degrees of freedom, can grasp and reorient an object using rolling contact with the rubber coated rollers  it is possible to create graspers that are highly capable but relatively simple by design. The active surface achieved by rolling and reorientation of the spherical rollers allow the grasper to perform in-hand manipulation without the need for ﬁnger gaiting. Rolling contact on the object can be viewed as a motion that continuously breaks contact with the object while simultaneously re-establishing contact at adjacent locations. The ability to reorient an object to any pose also lessens the need to use externally actuated degrees of freedom (e.g. actuation of the robotic arm and wrist) which simpliﬁes the control scheme. More importantly, the spherical design of the ﬁnger tips allows for stable grasps independent from the roller orientations, eliminating the need to analyze grasping modes for different combinations of roller orientations.  Learning robust policies for in-hand manipulation has been a long-standing challenge in robotics due to the complexity of modelling the object and grasper contacts and the difﬁculty of controlling ﬁnger motion in long and complicated manipulation sequences. Deep Reinforcement Learning (DRL) has been used to learn dexterous manipulation [13] [14]. However, learning to hold the object ﬁrmly and stably while transforming the object with deep reinforcement learning requires many more training episodes and a carefully designed reward function. To overcome these issues, we used an imitation learning based approach to learn a control policy in order to arbitrarily transform an object while holding it.              \f"}},"e607bf085b1648189880b0ceedb45643":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8e57a79c0624721b0bf2de2a0888744":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0ebc717e73b43c3a52967b50f5aff3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"15%"}},"f17fa9baddc549e4adea619453c78cec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1ab3e33d6e2404c9fb2a907279e4c7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc28e85dea7c4248a490626e86a336e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe14471e53994c2581b6edad81dc4a75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a6d4de2d62847019db85f5355daa494","placeholder":"​","style":"IPY_MODEL_a40ae8a807154111884513aa5622418a","value":"2014 IEEE International Conference on Robotics & Automation (ICRA) Hong Kong Convention and Exhibition Center May 31 - June 7, 2014. Hong Kong, China  978-1-4799-3685-4/14/$31.00 ©2014 IEEE  270  In-HandPreciseTwistingandPositioningbyaNovelDexterousRoboticGripperforIndustrialHigh-SpeedAssemblyFeiChen,Member,IEEE,FerdinandoCannella,Member,IEEE,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,andDarwinCaldwell,Fellow,IEEEAbstract—Inelectronicmanufacturingsystem,thedesignoftherobotichandwithsufﬁcientdexterityandconﬁgurationisimportantforthesuccessfulaccomplishmentoftheassemblytask.Duetothegrowingdemandfromhigh-mixmanufacturingindustry,itisdifﬁcultforthetraditionalrobottograspalargenumberofassemblypartsortoolshavingcylindershapeswithcorrectpostures.Inthisresearch,anoveljawlikegripperwithhuman-sizedanthropomorphicfeaturesisdesignedforin-handprecisepositioningandtwistingonline.Itretainsthesimplicityfeatureoftraditionalindustrialgrippersanddexterityfeaturesofdexterousgrippers.Itcanapplyaconstantgrippingforceonassemblypartsandperformsreliabletwistingmovementwithinlimitedtimetomeettheindustrialrequirements.Manipulatingseveralcylindricalassemblypartsbyrobot,asanexperimentalcaseinthispaper,isstudiedtoevaluateitsperformance.Theeffectivenessofproposedgripperdesignandmechanicalanalysisisprovedbythesimulationandexperimentalresults.I.INTRODUCTIONDuringthepasttensofyear,thedevelopmentinmanu-facturingindustryhasbeendividedintothreemainstreams:MassiveProduction,MediumProductionandSmallproduc-tion.Smallproduction,usuallyfullyusingrobots,cannotkeepinstepwiththegrowingsocialdemandingforHigh-Mix,Low-Volumemanufacturing.Forthemanufacturingfullywithhumanworkers,thelaborcostisalsoincreasingrapidly.Whenaddressingthisproblem,itisimportanttobuildmoreﬂexiblesystemstoimprovethedexterityandreconﬁgurabilityofcurrentmanufacturingsystembycon-sideringcombiningandcoordinatingtheabovetworespects,consideringtheirtrade-offandimprovingtheoverallas-semblyeffectivenessandefﬁciency[1].Fromourresearch,ifwecanprovidetherobotwithsufﬁcientﬂexibilityinreconﬁguration,itcanhelpthefactoryboostingtheproductqualityandmeanwhilereducingthecost[2].Currentlyinroboticassemblycellforﬂexiblemanufac-turing,therestillremainmanyunsolvedissuesforrobots.Oneisthattherobotcannotworkefﬁcientlyindealingwithassemblypartswithcomplicatedshapes.Theyoftenrelyonexternalsensorsystemstohelpwiththeassemblywork[3].Ontheotherside,humanworkersareskilledinperformingcomplicatedtasksusingtheirhands.Inthiscase,itisessentialthattheconventionalroboticmanipulatorisabletoperformcomplicatedmanipulationlikehumanworkerFeiChen,FerdinandoCannella,CarloCanali,TravelerHauptman,GiuseppeSoﬁa,DarwinCaldwellarewithintheDepartmentofAdvancedRobotics,IstitutoItalianodiTecnologia,Italy,16163,E-mail:{fei.chen,ferdinando.cannella,carlo.canali,traveler.hauptman,giuseppe.soﬁa,dar-win.caldwell}@iit.it.Fig.1.AssemblyscenariointhisresearchunderAUTORECONproject[4].TheobjectiveofAUTORECONprojectistodesignamanufacturingsystemwithreconﬁgurableroboticmanipulatorunderthewellcontrolledinformationﬂow.Todesignseveralreconﬁgurablerobotichandssuitableforindustrialimplementationisoneofitstasks.does.Duringthepastyearsofdevelopmentinroboticmanip-ulators,nevertheless,thebasicappearanceofthemanipulatorhasseldomchanged,anditisalsodifﬁcultontheotherhandtomodifythebasicarchitectureofrobots.Therefore,peopletendtoimprovethecapacityofrobotsbydesigningvariousfunctionalend-effectors(hands)forrobots.Inordertomeetindustrialapplicationrequirements,therobotichandsmustbeinexpensive,compact,lowweightandrobust.Italsomustbecapableofperformingsimplegraspingandmanipulationtasks,suchasprecisionmanipulation,in-handgrasptransitions,andsufﬁcientlygeneraltomanipulatedifferentobjectsandtools.Uptopresent,mostrobotichandsinbothindustrialandacademicworldsareeitherfewactuatorspoweredjaws,orsimpliﬁedhumanhandshapelikedmulti-ﬁngeredhandsforcertaingraspingpatterns.Lotsofresearchershavealreadypaidmuchattentiontodevelopsuchfunctionalroboticend-effectorsinthepast25years.Aroboticgrippercouldbeoftwoﬁngers,likeajaw[3]withtwoﬁngersinourpreviousresearch,threeﬁngers[5]orfourﬁngers[6]orevenmore,thesamewithhuman’shand[7].Parallelmanipulator[8]hasbeenalreadysuccessfullyimplementedinindustry.Theycanperformanddemonstratepickandplaceoperationsinreallyfastspeedwithhighreliability[9].Meanwhile,itismuchcheaperandsimplerthanserialmanipulators.Itiswidelyadoptedinhighspeed,high-accuracypositioningwithinonlylimitedworkspace,suchasfoodpackingandelectronicpartsplacing.Anothernoveluniversalgrippersisdeveloped,whichisabletopickupunfamiliarobjectsofwidelyvarying\f"}}}}},"nbformat":4,"nbformat_minor":0}
