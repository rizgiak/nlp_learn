{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'edgar_allan_poe.txt' already there; not retrieving.\n",
      "\n",
      "File 'robert_frost.txt' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt -e https_proxy=http://daicelproxy3:80\n",
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt -e https_proxy=http://daicelproxy3:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "    'edgar_allan_poe.txt',\n",
    "    'robert_frost.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO! Death hath rear'd himself a throne\n",
      "In a strange city, all alone,\n",
      "Far down within the dim west\n",
      "Where the good, and the bad, and the worst, and the best,\n",
      "Have gone to their eternal rest.\n",
      "â€‰\n",
      "There shrines, and palaces, and towers\n",
      "Are not like any thing of ours\n",
      "Oh no! O no! ours never loom\n",
      "To heaven with that ungodly gloom!\n"
     ]
    }
   ],
   "source": [
    "!head edgar_allan_poe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth; \n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim\n",
      "Because it was grassy and wanted wear,\n",
      "Though as for that the passing there\n"
     ]
    }
   ],
   "source": [
    "!head robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edgar_allan_poe.txt corresponds to label 0\n",
      "robert_frost.txt corresponds to label 1\n"
     ]
    }
   ],
   "source": [
    "# collect data into lists\n",
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "for label, f in enumerate(input_files):\n",
    "    print(f\"{f} corresponds to label {label}\")\n",
    "\n",
    "    for line in open(f):\n",
    "        line = line.rstrip().lower()\n",
    "        if line:\n",
    "            # remove punctuation\n",
    "            line = line.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "            input_texts.append(line)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, Ytrain, Ytest = train_test_split(input_texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615, 539)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ytrain), len(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shall dawn upon him desolate',\n",
       " 'what do we see in such a hole i wonder',\n",
       " 'what childishness he wouldnt give way to',\n",
       " 'it makes it all the worse you must be blind',\n",
       " 'waiting for things to happen in their favour']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['only bewitched so i would last him longer',\n",
       " 'and a trapper looking in at the door',\n",
       " 'who alterest all things with thy peering eyes',\n",
       " 'she was shut in for life she lived her whole',\n",
       " 'on fathers side it seems were let me see  ']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "word2idx = {\"<unk>\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx\n",
    "for text in train_text:\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = idx\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2523"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into integer format\n",
    "\n",
    "train_text_int = []\n",
    "test_text_int = []\n",
    "\n",
    "for text in train_text:\n",
    "    tokens = text.split()\n",
    "    line_as_int = [word2idx[token] for token in tokens]\n",
    "    train_text_int.append(line_as_int)\n",
    "\n",
    "for text in test_text:\n",
    "    tokens = text.split()\n",
    "    line_as_int = [word2idx.get(token, 0) for token in tokens]\n",
    "    test_text_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[390, 25, 391, 93, 35, 153],\n",
       " [392, 25, 393, 47, 49, 394, 69, 180],\n",
       " [102, 25, 395, 69, 396, 105],\n",
       " [69, 14, 397, 12, 398, 399, 90, 400],\n",
       " [14, 401, 21, 402, 27, 21, 25, 403]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_int[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[174, 45, 108, 63, 0, 47, 1859, 0],\n",
       " [50, 1135, 664, 47, 24, 29, 0],\n",
       " [72, 350, 1130, 2465],\n",
       " [583, 334, 664, 0, 0, 0],\n",
       " [465, 0, 81, 25, 0, 420, 0]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_int[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize A and pi matrices - for both classes\n",
    "V = len(word2idx)\n",
    "\n",
    "A0 = np.ones((V, V))\n",
    "pi0 = np.ones(V)\n",
    "\n",
    "A1 = np.ones((V, V))\n",
    "pi1 = np.ones(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for A and pi\n",
    "\n",
    "def compute_counts(text_as_int, A, pi):\n",
    "    for tokens in text_as_int:\n",
    "        last_idx = None\n",
    "        for idx in tokens:\n",
    "            if last_idx is None:\n",
    "                # its the first word in a sentence\n",
    "                pi[idx] += 1\n",
    "            else:\n",
    "                # the last word exists, so count a transition\n",
    "                A[last_idx, idx] += 1\n",
    "            \n",
    "            # update last idx\n",
    "            last_idx = idx\n",
    "\n",
    "\n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 0], A0, pi0)\n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 1], A1, pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize A and pi so they are valid probability matrices\n",
    "# convince yourself that this is equivalent to the formulas shown before\n",
    "\n",
    "A0 /= A0.sum(axis=1, keepdims=True)\n",
    "pi0 /= pi0.sum()\n",
    "\n",
    "A1 /= A1.sum(axis=1, keepdims=True)\n",
    "pi1 /= pi1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log A and pi since we dont need the actual probs\n",
    "logA0 = np.log(A0)\n",
    "logpi0 = np.log(pi0)\n",
    "\n",
    "logA1 = np.log(A1)\n",
    "logpi1 = np.log(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33436532507739936, 0.6656346749226006)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute priors\n",
    "count0 = sum(y == 0 for y in Ytrain)\n",
    "count1 = sum(y == 1 for y in Ytrain)\n",
    "total = len(Ytrain)\n",
    "p0 = count0 / total\n",
    "p1 = count1 / total\n",
    "logp0 = np.log(p0)\n",
    "logp1 = np.log(p1)\n",
    "p0, p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classifier\n",
    "class Classifier:\n",
    "    def __init__(self, logAs, logpis, logpriors):\n",
    "        self.logAs = logAs\n",
    "        self.logpis = logpis\n",
    "        self.logpriors = logpriors\n",
    "        self.K = len(logpriors) # number of classes\n",
    "\n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        logA = self.logAs[class_]\n",
    "        logpi = self.logpis[class_]\n",
    "\n",
    "        last_idx = None\n",
    "        logprob = 0\n",
    "        for idx in input_:\n",
    "            if last_idx is None:\n",
    "                #its the first token\n",
    "                logprob += logpi[idx]\n",
    "            else:\n",
    "                logprob += logA[last_idx, idx]\n",
    "\n",
    "            # update last_idx\n",
    "            last_idx = idx\n",
    "        \n",
    "        return logprob\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        predictions = np.zeros(len(inputs))\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] for c in range(self.K)]\n",
    "            pred = np.argmax(posteriors)\n",
    "            predictions[i] = pred\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array must be in order since classes are assumed to index these lists\n",
    "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9956656346749226\n",
      "Test acc: 0.8200371057513914\n"
     ]
    }
   ],
   "source": [
    "Ptrain = clf.predict(train_text_int)\n",
    "print(f\"Train acc: {np.mean(Ptrain == Ytrain)}\")\n",
    "Ptest = clf.predict(test_text_int)\n",
    "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 533,    7],\n",
       "       [   0, 1075]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Ytrain, Ptrain)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91,  87],\n",
       "       [ 10, 351]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(Ytest, Ptest)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1: 0.9967547519703291\n",
      "Test f1: 0.8785982478097621\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train f1: {f1_score(Ytrain, Ptrain)}\")\n",
    "print(f\"Test f1: {f1_score(Ytest, Ptest)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
